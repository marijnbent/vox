This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
.roo/
  mcp.json
resources/
  default-prompt.txt
  key-monitor.swift
  README.md
src/
  main/
    enhancement/
      EnhancementManager.ts
      EnhancementService.ts
      OpenaiEnhancementService.ts
    modules/
      ipcHandlers.ts
      shortcutManager.ts
      windowManager.ts
    transcription/
      DeepgramService.ts
      LocalWhisperService.ts
      OpenaiWhisperService.ts
      TranscriptionManager.ts
      TranscriptionService.ts
    historyService.ts
    index.ts
    logger.ts
    store.ts
  preload/
    index.d.ts
    index.ts
    widget.d.ts
    widget.ts
  renderer/
    src/
      assets/
        main.css
        widget.css
      components/
        layout/
          AppLayout.svelte
          StatusIndicator.svelte
        settings/
          Dashboard.svelte
          Dictionary.svelte
          Enhancements.svelte
          History.svelte
          Permissions.svelte
          Shortcuts.svelte
          Transcription.svelte
        WaterWaveAnimation.svelte
      lib/
        audioRecorder.ts
      App.svelte
      env.d.ts
      main.ts
      widget.ts
      WidgetApp.svelte
    index.html
    widget.html
.editorconfig
.gitignore
.prettierignore
.prettierrc.yaml
dev-app-update.yml
electron-builder.yml
electron.vite.config.ts
eslint.config.mjs
package.json
plan.md
README.md
svelte.config.mjs
tsconfig.json
tsconfig.node.json
tsconfig.web.json

================================================================
Files
================================================================

================
File: .roo/mcp.json
================
{
  "mcpServers": {
    "deepgram-js-sdk Docs": {
      "url": "https://gitmcp.io/deepgram/deepgram-js-sdk",
      "disabled": false,
      "autoApprove": []
    },
    "electron Docs": {
      "url": "https://gitmcp.io/electron/electron",
      "disabled": false,
      "autoApprove": []
    },
    "svelte Docs": {
      "disabled": false,
      "autoApprove": [],
      "url": "https://gitmcp.io/sveltejs/svelte"
    },
    "daisyui Docs": {
      "disabled": false,
      "autoApprove": [],
      "url": "https://gitmcp.io/saadeghi/daisyui"
    }
  }
}

================
File: resources/default-prompt.txt
================
You are tasked with cleaning up text that has been transcribed from voice. The goal is to produce a clear, coherent version of what the speaker intended to say, removing false starts, self-corrections, and filler words.

Follow these steps to clean up the text:

1. Remove filler words and phrases such as "um", "uh", "like", "you know", "I mean", etc.
2. Identify and remove false starts. These are instances where the speaker begins a sentence or phrase but then restarts or changes direction.
3. When the speaker corrects themselves, keep only the corrected version. For example, if the text says "The user need to, I mean, the user can do", retain only "The user can do".
4. Maintain the original meaning and intent of the speaker. Do not add new information or change the substance of what was said.
5. Ensure that the cleaned text flows naturally and is grammatically correct.
6. Preserve any important pauses or breaks in thought by using appropriate punctuation.
7. For very short texts (e.g., single words or brief phrases), remove the ending period if present and do not capitalize the first word.

Here are some examples to illustrate the process:
Original: "So, um, the thing is, you know, we need to, uh, I mean, we should probably look into this further."
Cleaned: "We should probably look into this further."

Original: "The project will take about two weeks, no, sorry, three weeks to complete."
Cleaned: "The project will take about three weeks to complete."

Original: "We're going to discuss the new, uh, the upcoming changes to the policy."
Cleaned: "We're going to discuss the upcoming changes to the policy."

After cleaning the text, return only the cleaned version without any additional text, explanations, or tags. The output should be ready for direct use without further editing.

Here is the transcribed text:
{{transcription}}

{{#dictionary_words}}
Words that the user added to its dictionary. Replace if you think the word was transcribed differently.
{{dictionary_words}}
{{/dictionary_words}}

{{#context_input_field}}
{{context_input_field}}
{{/context_input_field}}

{{#context_clipboard}}
{{context_clipboard}}
{{/context_clipboard}}

{{#context_screen}}
{{context_screen}}
{{/context_screen}}

================
File: resources/key-monitor.swift
================
import Foundation
import CoreGraphics
import AppKit // For NSEvent.ModifierFlags constants

// --- Key Definitions ---
struct MonitoredKey {
    let name: String
    let keyCode: CGKeyCode      // Specific key code (e.g., 55 for Left Command)
    let flag: CGEventFlags?     // Corresponding flag mask (e.g., .maskCommand)
    var isDown: Bool = false
}

// Global mutable state
var keysToMonitor: [MonitoredKey] = []
var eventTap: CFMachPort?
var runLoopSource: CFRunLoopSource?

// --- Argument Parsing ---
let arguments = CommandLine.arguments
if arguments.count < 2 {
    FileHandle.standardError.write("Usage: \(arguments[0]) KEY1 KEY2 ... (e.g., COMMAND OPTION SHIFT)\n".data(using: .utf8)!)
    exit(1)
}
let requestedKeys = Set(arguments.dropFirst().map { $0.uppercased() })

// Map names to key codes AND flags
// 55: Left Command, 54: Right Command -> .maskCommand
// 58: Left Option, 61: Right Option -> .maskAlternate
// 56: Left Shift, 60: Right Shift -> .maskShift
// 59: Left Control, 62: Right Control -> .maskControl
// 63: Fn key -> .maskSecondaryFn
if requestedKeys.contains("COMMAND") {
    // keysToMonitor.append(MonitoredKey(name: "COMMAND", keyCode: 55, flag: .maskCommand)) // Left
    keysToMonitor.append(MonitoredKey(name: "COMMAND", keyCode: 54, flag: .maskCommand)) // Right
}

if requestedKeys.contains("OPTION") {
    // keysToMonitor.append(MonitoredKey(name: "OPTION", keyCode: 58, flag: .maskAlternate)) // Left
    keysToMonitor.append(MonitoredKey(name: "OPTION", keyCode: 61, flag: .maskAlternate)) // Right
}

if requestedKeys.contains("CONTROL") {
    // keysToMonitor.append(MonitoredKey(name: "CONTROL", keyCode: 59, flag: .maskControl)) // Left
    keysToMonitor.append(MonitoredKey(name: "CONTROL", keyCode: 62, flag: .maskControl)) // Right
}

if requestedKeys.contains("FN") {
    keysToMonitor.append(MonitoredKey(name: "FN", keyCode: 63, flag: .maskSecondaryFn))
}

// Add Escape key monitoring (keyCode 53)
keysToMonitor.append(MonitoredKey(name: "ESCAPE", keyCode: 53, flag: nil))

if keysToMonitor.isEmpty {
    FileHandle.standardError.write("No valid keys specified to monitor.\n".data(using: .utf8)!)
    exit(1)
}

// --- CGEventTap Callback ---
let eventCallback: CGEventTapCallBack = { (proxy, type, event, refcon) -> Unmanaged<CGEvent>? in

    // Handle Escape key separately on keyDown
    if type == .keyDown {
        let escapeKeyCode = CGKeyCode(53)
        let currentKeyCode = CGKeyCode(event.getIntegerValueField(.keyboardEventKeycode))
        if currentKeyCode == escapeKeyCode {
            FileHandle.standardOutput.write("ESCAPE_DOWN\n".data(using: .utf8)!)
            fflush(stdout)
        }
    }

    // Process modifier keys (Command, Option, etc.) for keyDown, keyUp, flagsChanged
    guard type == .keyDown || type == .keyUp || type == .flagsChanged else {
        return Unmanaged.passRetained(event) // Should not be reached if Escape was handled above, but keep for safety
    }

    var keyCode: CGKeyCode? = nil
    if type == .keyDown || type == .keyUp {
        keyCode = CGKeyCode(event.getIntegerValueField(.keyboardEventKeycode))
    }
    let currentFlags = event.flags

    // Iterate through the *modifier* keys we are specifically monitoring (excluding Escape)
    for i in 0..<keysToMonitor.count {
        // Skip processing Escape key here as it's handled above
        if keysToMonitor[i].name == "ESCAPE" {
            continue
        }

        var key = keysToMonitor[i] // Mutable copy
        var stateChanged = false
        var isKeyDownNow: Bool? = nil // Use optional to see if state was determined

        // Method 1: Direct KeyCode match (priority for modifiers)
        if let code = keyCode, key.keyCode == code {
             isKeyDownNow = (type == .keyDown)
        }
        // Method 2: FlagsChanged event - check corresponding flag (fallback for modifiers)
        else if type == .flagsChanged, let flag = key.flag {
             isKeyDownNow = currentFlags.contains(flag)
        }

        // If we determined a state for this modifier key in this event
        if let determinedState = isKeyDownNow {
            // Check if it's different from the last known state
            if key.isDown != determinedState {
                stateChanged = true
                key.isDown = determinedState // Update state
                keysToMonitor[i] = key      // Write back to global array
            }
        }

        // If the state for this specific modifier key actually changed
        if stateChanged {
            let stateString = key.isDown ? "DOWN" : "UP"
            FileHandle.standardOutput.write("\(key.name)_\(stateString)\n".data(using: .utf8)!)
            fflush(stdout)
        }
    }

    // Re-enable tap if it gets disabled
    if type == .tapDisabledByTimeout || type == .tapDisabledByUserInput {
         if let tap = eventTap {
             CGEvent.tapEnable(tap: tap, enable: true)
         }
    }

    return Unmanaged.passRetained(event)
}

// --- Setup CGEventTap ---
// (Setup logic remains the same as the previous working version)
func setupEventTap() -> Bool {
    let eventMask = (1 << CGEventType.keyDown.rawValue) |
                    (1 << CGEventType.keyUp.rawValue) |
                    (1 << CGEventType.flagsChanged.rawValue)

    eventTap = CGEvent.tapCreate(tap: .cgSessionEventTap,
                                 place: .headInsertEventTap,
                                 options: .defaultTap,
                                 eventsOfInterest: CGEventMask(eventMask),
                                 callback: eventCallback,
                                 userInfo: nil)

    guard let eventTap = eventTap else {
        FileHandle.standardError.write("Failed to create event tap. Ensure Accessibility permissions are granted.\n".data(using: .utf8)!)
        fflush(stderr)
        return false
    }

    runLoopSource = CFMachPortCreateRunLoopSource(kCFAllocatorDefault, eventTap, 0)
    guard let runLoopSource = runLoopSource else {
        FileHandle.standardError.write("Failed to create run loop source.\n".data(using: .utf8)!)
        fflush(stderr)
        return false
    }
    CFRunLoopAddSource(CFRunLoopGetCurrent(), runLoopSource, .commonModes)

    CGEvent.tapEnable(tap: eventTap, enable: true)
    FileHandle.standardOutput.write("Event tap created successfully (Listening to KeyDown/Up/FlagsChanged).\n".data(using: .utf8)!)
    fflush(stdout)
    return true
}

// --- Main Execution ---
if !setupEventTap() {
    exit(1)
}

let monitoredNames = Set(keysToMonitor.map { $0.name }).joined(separator: ", ")
FileHandle.standardOutput.write("Monitoring keys: \(monitoredNames)...\n".data(using: .utf8)!)
fflush(stdout)

CFRunLoopRun()

// Cleanup
FileHandle.standardOutput.write("Exiting...\n".data(using: .utf8)!)
fflush(stdout)
if let tap = eventTap { CGEvent.tapEnable(tap: tap, enable: false) }

exit(0)

================
File: resources/README.md
================
# Key Monitor

To compile:

```bash
swiftc key-monitor.swift -o key-monitor -framework CoreGraphics -framework AppKit
```

================
File: src/main/enhancement/EnhancementManager.ts
================
import fs from 'fs';
import path from 'path';
import { app } from 'electron';
import { EnhancementService } from './EnhancementService';
import { OpenaiEnhancementService } from './OpenaiEnhancementService';
import store from '../store';
import { logger } from '../logger';
import type { EnhancementSettings, EnhancementPrompt } from '../store';

export function getDefaultPromptTemplate(): string {
  try {
    const basePath = app.isPackaged
        ? process.resourcesPath
        : app.getAppPath();
    const filePath = path.join(basePath, 'resources', 'default-prompt.txt');

    if (fs.existsSync(filePath)) {
      logger.debug(`Loading default prompt from: ${filePath}`);
      return fs.readFileSync(filePath, 'utf-8');
    } else {
      logger.error(`Default prompt file not found at: ${filePath}. Using fallback.`);
      return `Please enhance the following transcription for clarity, grammar, and formatting. Keep the original meaning intact:\n\n{{transcription}}`;
    }
  } catch (error) {
    logger.error('Error reading default prompt file:', error);
    return `Please enhance the following transcription for clarity, grammar, and formatting. Keep the original meaning intact:\n\n{{transcription}}`;
  }
}

export class EnhancementManager {
  private enhancementService: EnhancementService;

  constructor() {
    this.enhancementService = new OpenaiEnhancementService();
    logger.info('Enhancement Manager initialized using OpenaiEnhancementService for all providers.');
  }

  private getActivePromptTemplate(settings: EnhancementSettings): string {
    if (settings.activePromptId === 'default') {
      return getDefaultPromptTemplate();
    }
    const customPrompts = store.get('enhancementPrompts', []) as EnhancementPrompt[];
    const activePrompt = customPrompts.find(p => p.id === settings.activePromptId);
    if (activePrompt) {
      logger.info(`Using custom enhancement prompt: ${activePrompt.name}`);
      return activePrompt.template;
    } else {
      logger.warn(`Active custom prompt ID "${settings.activePromptId}" not found. Falling back to default prompt.`);
      return getDefaultPromptTemplate();
    }
  }

  public async enhance(text: string): Promise<string> {
    const settings = store.get('enhancements') as EnhancementSettings;

    if (text === '') {
      logger.warn('EnhancementManager: No text provided for enhancement. Skipping enhancement.');
      return text;
    }
    
    if (!settings.enabled) {
      logger.info('Enhancement disabled. Skipping enhancement.');
      return text;
    }

    const promptTemplate = this.getActivePromptTemplate(settings);
    let apiKey = '';
    let model = '';
    let apiEndpoint: string | undefined = undefined;

    switch (settings.provider) {
      case 'openai':
        apiKey = settings.openaiApiKey;
        model = settings.openaiModel;
        break;
      case 'gemini':
        apiKey = settings.geminiApiKey;
        model = settings.geminiModel;
        apiEndpoint = "https://generativelanguage.googleapis.com/v1beta/openai/";
        break;
      case 'custom':
        apiKey = settings.customApiKey;
        model = settings.customModelName;
        apiEndpoint = settings.customBaseUrl || undefined;
        break;
      default:
        logger.error(`EnhancementManager: Invalid provider "${settings.provider}" encountered.`);
        return text; 
    }

    if (!apiKey) {
        logger.warn(`EnhancementManager: API key for provider "${settings.provider}" is missing. Skipping enhancement.`);
        return text;
    }
     if (!model) {
        logger.warn(`EnhancementManager: Model for provider "${settings.provider}" is missing. Skipping enhancement.`);
        return text;
    }

    logger.info(`EnhancementManager: Enhancing text via OpenAI-compatible service using provider "${settings.provider}" settings (Model: "${model}", Endpoint: ${apiEndpoint || 'Default'}).`);
    try {
      const enhancedText = await this.enhancementService.enhance(
          text,
          promptTemplate,
          apiKey,
          model,
          apiEndpoint
      );
      logger.info('EnhancementManager: Enhancement successful.');
      return enhancedText;
    } catch (error) {
      logger.error(`EnhancementManager: Error during enhancement using ${settings.provider} settings:`, error);
      return text;
    }
  }
}

================
File: src/main/enhancement/EnhancementService.ts
================
export interface EnhancementService {
  /**
   * Enhances the given text using a specific prompt template.
   * @param text The original transcribed text.
   * @param promptTemplate The prompt template (e.g., "Fix this text: {{transcription}}").
   * @param apiKey The API key for the service.
   * @param model The specific model to use.
   * @param apiEndpoint Optional endpoint for custom providers.
   * @returns The enhanced text.
   */
  enhance(
    text: string,
    promptTemplate: string,
    apiKey: string,
    model: string,
    apiEndpoint?: string
  ): Promise<string>;
}

================
File: src/main/enhancement/OpenaiEnhancementService.ts
================
import OpenAI from 'openai';
import Mustache from 'mustache';
import { EnhancementService } from './EnhancementService';
import { logger } from '../logger';
import store from '../store';
import type { EnhancementSettings } from '../store';

export class OpenaiEnhancementService implements EnhancementService {
  async enhance(
    text: string,
    promptTemplate: string,
    apiKey: string,
    model: string,
    baseURL?: string
  ): Promise<string> {

    if (!apiKey) {
      logger.error('OpenAI Enhancement: API key is missing.');
      throw new Error('OpenAI API key for enhancement is required.');
    }

    const openai = new OpenAI({
      apiKey: apiKey,
      baseURL: baseURL || undefined
    });

    const contextData: { [key: string]: any } = {
      transcription: text
    };
    const enhancementSettings = store.get('enhancements') as EnhancementSettings;

    if (enhancementSettings.useContextScreen) {
      contextData.context_screen = "[Screen Content Placeholder - Not Implemented]";
    }
    if (enhancementSettings.useContextInputField) {
      contextData.context_input_field = "[Input Field Placeholder - Not Implemented]";
    }
    if (enhancementSettings.useContextClipboard) {
      contextData.context_clipboard = "[Clipboard Placeholder - Not Implemented]";
    }
    if (enhancementSettings.useDictionaryWordList) {
      const dictionaryWords = store.get('dictionary.words', []) as string[];
      contextData.dictionary_word_list = dictionaryWords.join(', ');
    }

    logger.debug('Rendering prompt template with context:', contextData);
    const finalPrompt = Mustache.render(promptTemplate, contextData);
    logger.debug(`Final rendered prompt: ${finalPrompt.substring(0, 100)}...`);

    logger.info(`Sending enhancement request to OpenAI model ${model}...`);

    try {
      const completion = await openai.chat.completions.create({
        messages: [
          { role: 'user', content: finalPrompt }
        ],
        model: model,
        temperature: 0.5,
        max_tokens: Math.max(100, text.length * 2),
      });

      const enhancedText = completion.choices[0]?.message?.content;

      if (enhancedText) {
        logger.info('OpenAI Enhancement successful.');
        return enhancedText.trim();
      } else {
        logger.error('OpenAI Enhancement: Received empty response from API.');
        throw new Error('OpenAI enhancement returned an empty response.');
      }
    } catch (error: unknown) {
      const message = error instanceof Error ? error.message : String(error);
      logger.error('OpenAI Enhancement failed:', error);
      throw new Error(`OpenAI enhancement failed: ${message}`);
    }
  }
}

================
File: src/main/modules/ipcHandlers.ts
================
import Mustache from 'mustache';
import { ipcMain, systemPreferences, shell, clipboard, app } from 'electron';
import { exec } from 'child_process';
import store from '../store';
import { logger } from '../logger';
import { TranscriptionManager } from '../transcription/TranscriptionManager';
import { EnhancementManager, getDefaultPromptTemplate } from '../enhancement/EnhancementManager';
import * as historyService from '../historyService';
import { startKeyMonitor } from './shortcutManager';
import { getMainWindow, sendToMain, sendToWidget } from './windowManager';
import type { EnhancementPrompt, EnhancementSettings } from '../store';
import type { HistoryRecord } from '../historyService';
import { LocalWhisperService, AVAILABLE_LOCAL_MODELS } from '../transcription/LocalWhisperService';

let transcriptionManager: TranscriptionManager;
let enhancementManager: EnhancementManager;

export function initializeIpcHandlers(dependencies: {
    transcriptionManager: TranscriptionManager;
    enhancementManager: EnhancementManager;
    getProcessingCancelledFlag: () => boolean;
    setProcessingCancelledFlag: (value: boolean) => void;
    sendRecordingStatus: (status: 'idle' | 'recording' | 'processing' | 'error') => void;
}): void {
    transcriptionManager = dependencies.transcriptionManager;
    enhancementManager = dependencies.enhancementManager;
    _getProcessingCancelledFlag = dependencies.getProcessingCancelledFlag;
    _setProcessingCancelledFlag = dependencies.setProcessingCancelledFlag;
    _sendRecordingStatus = dependencies.sendRecordingStatus;
    logger.info('IPC Handlers initialized with dependencies.');
}

let _getProcessingCancelledFlag: () => boolean = () => false;
let _setProcessingCancelledFlag: (value: boolean) => void = () => {};
let _sendRecordingStatus: (status: 'idle' | 'recording' | 'processing' | 'error') => void = () => {};

export function setupIpcHandlers(): void {
    logger.info('Setting up IPC Handlers...');

    ipcMain.handle('getStoreValue', (_, key: string) => {
        logger.debug(`IPC: Handling getStoreValue for key: ${key}`);
        try {
            const value = store.get(key);
            logger.debug(`IPC: Value for ${key}:`, value);
            return value;
        } catch (error) {
            logger.error(`IPC: Error getting store value for key ${key}:`, error);
            throw error;
        }
    });
    ipcMain.handle('setStoreValue', (_, key: string, value: unknown) => {
        logger.debug(`IPC: Handling setStoreValue for key: ${key} with value:`, value);
        try {
            store.set(key, value);
            logger.debug(`IPC: Successfully set store value for key: ${key}`);
        } catch (error) {
            logger.error(`IPC: Error setting store value for key ${key}:`, error);
            throw error;
        }
    });

    ipcMain.handle('updateMonitoredKeys', (_, keys: string[]) => {
        logger.info('IPC: Received request to update monitored keys:', keys);
        if (process.platform === 'darwin') {
            const validKeys = keys.map(k => k.toUpperCase()).filter(k => ["COMMAND", "OPTION", "CONTROL", "SHIFT", "FN"].includes(k));
            startKeyMonitor(validKeys);
        } else {
            logger.warn('IPC: Key monitoring only supported on macOS.');
        }
    });

    ipcMain.handle('transcribe-audio', handleTranscribeAudio);

    ipcMain.handle('getAccessibilityStatus', handleGetAccessibilityStatus);
    ipcMain.handle('requestAccessibilityAccess', handleRequestAccessibilityAccess);
    ipcMain.handle('getMediaPermissionStatus', handleGetMediaPermissionStatus);
    ipcMain.handle('requestMediaPermission', handleRequestMediaPermission);
    ipcMain.handle('openSettingsURL', handleOpenSettingsURL);

    ipcMain.handle('getHistory', (_, page?: number, pageSize?: number) => {
        logger.info(`IPC: Received request for history page ${page || 1}`);
        return historyService.getHistoryEntries(page, pageSize);
    });
    ipcMain.handle('deleteHistoryEntry', (_, id: string) => {
         logger.info(`IPC: Received request to delete history entry ${id}`);
         return historyService.deleteHistoryEntry(id);
    });
    ipcMain.handle('clearAllHistory', () => {
         logger.info(`IPC: Received request to clear all history`);
         return historyService.clearAllHistory();
    });

    ipcMain.handle('download-local-model', async (_event, modelName: string): Promise<void> => {
        logger.info(`IPC received request to download local model: ${modelName}`);
        if (!AVAILABLE_LOCAL_MODELS.includes(modelName)) {
            logger.error(`Invalid model name requested for download: ${modelName}`);
            throw new Error(`Invalid model name: ${modelName}`);
        }
        try {
            await LocalWhisperService.downloadModel(modelName);
            logger.info(`Local model download process initiated successfully for: ${modelName}`);
        } catch (error: any) {
            logger.error(`Error initiating local model download for ${modelName}:`, error);
            throw new Error(`Failed to download model ${modelName}: ${error.message || 'Unknown error'}`);
        }
    });

    ipcMain.on('processing-cancelled-silence', handleProcessingCancelledSilence);

    ipcMain.on('widget-stop-recording', () => {
        logger.info('Received stop recording request from widget');
        sendToMain('stop-recording');
    });

    ipcMain.on('recorder-actually-started', () => {
        logger.debug('IPC: Received notification that recorder actually started.');
        sendToWidget('widget-recorder-started');
    });

    ipcMain.handle('getDefaultPromptContent', () => {
      return getDefaultPromptTemplate();
    });

    logger.info('IPC Handlers setup complete.');
}

async function handleTranscribeAudio(_, audio: { audioData: ArrayBuffer; mimeType: string }): Promise<void> {
    _setProcessingCancelledFlag(false);
    const mainWindow = getMainWindow();

    if (!transcriptionManager) {
        logger.error('IPC: Cannot transcribe audio, TranscriptionManager not initialized.');
        _sendRecordingStatus('error');
        throw new Error('TranscriptionManager not initialized.');
    }
    if (!mainWindow) {
        logger.error('IPC: Cannot transcribe audio, mainWindow is not available.');
        _sendRecordingStatus('error');
        throw new Error('Main window not available.');
    }

    logger.info(`IPC: Received audio data (${audio.audioData.byteLength} bytes, type: ${audio.mimeType}) for transcription.`);
    _sendRecordingStatus('processing');

    let originalTranscriptionText = '';
    let finalText = '';
    let enhancementAttempted = false;
    let finalPromptRendered: string | null = null;

    try {
        if (_getProcessingCancelledFlag()) {
            logger.info('Processing cancelled by Escape before transcription.');
            return;
        }

        const audioBuffer = Buffer.from(audio.audioData);
        originalTranscriptionText = await transcriptionManager.transcribe(audioBuffer, audio.mimeType, undefined);
        finalText = originalTranscriptionText;
        logger.info(`IPC: Transcription successful: "${originalTranscriptionText}"`);

        if (_getProcessingCancelledFlag()) {
            logger.info('Processing cancelled by Escape after transcription.');
            return;
        }

        const enhancementSettings = store.get('enhancements') as EnhancementSettings;
        if (enhancementManager && enhancementSettings.enabled && !_getProcessingCancelledFlag()) {
            enhancementAttempted = true;
            try {
                logger.info('Applying enhancement...');
                 const activePromptId = enhancementSettings.activePromptId;
                 const customPrompts = store.get('enhancementPrompts', []) as EnhancementPrompt[];
                 const activePrompt = customPrompts.find(p => p.id === activePromptId);

                 const activeTemplate = activePromptId === 'default'
                     ? getDefaultPromptTemplate()
                     : activePrompt?.template ?? getDefaultPromptTemplate();

                 const contextData: { [key: string]: any } = { transcription: originalTranscriptionText };
                 if (enhancementSettings.useContextScreen) {
                   contextData.context_screen = "[Screen Content Placeholder - Not Implemented]";
                 }
                 if (enhancementSettings.useContextInputField) {
                   contextData.context_input_field = "[Input Field Placeholder - Not Implemented]";
                 }
                 if (enhancementSettings.useContextClipboard) {
                   contextData.context_clipboard = "[Clipboard Placeholder - Not Implemented]";
                 }
                 if (enhancementSettings.useDictionaryWordList) {
                   const dictionaryWords = store.get('dictionary.words', []) as string[];
                   contextData.dictionary_word_list = dictionaryWords.join(', ');
                 }

                 try {
                     finalPromptRendered = Mustache.render(activeTemplate, contextData);
                     logger.debug(`IPC: Rendered prompt for history: ${finalPromptRendered.substring(0,100)}...`);
                 } catch (renderError) {
                     logger.error('IPC: Error rendering prompt for history:', renderError);
                     finalPromptRendered = activeTemplate;
                 }

                 const enhancedTextResult = await enhancementManager.enhance(originalTranscriptionText);

                 if (enhancedTextResult !== originalTranscriptionText) {
                     logger.info(`IPC: Enhancement successful: "${enhancedTextResult}"`);
                     finalText = enhancedTextResult;
                 } else {
                     logger.info('Enhancement did not modify the text.');
                 }
            } catch (enhancementError) {
                logger.error('Enhancement step failed:', enhancementError);
                finalPromptRendered = null;
            }
        } else if (_getProcessingCancelledFlag()) {
             logger.info('Enhancement skipped due to cancellation.');
        } else {
            logger.info('Enhancement disabled or provider is none, skipping.');
        }

        if (_getProcessingCancelledFlag()) {
            logger.info('Processing cancelled by Escape before history/paste.');
            return;
        }

        try {
            let promptIdForHistory: string | null = null;
            if (enhancementAttempted) {
                promptIdForHistory = store.get('enhancements.activePromptId') as string ?? null;
            }
            const historyEntryData: Omit<HistoryRecord, 'id' | 'timestamp'> = {
                originalText: originalTranscriptionText,
                renderedPrompt: finalPromptRendered,
                enhancedText: finalText !== originalTranscriptionText ? finalText : null,
                promptIdUsed: promptIdForHistory
            };
            historyService.addHistoryEntry(historyEntryData);
        } catch(historyError) {
             logger.error('Failed to save transcription to history:', historyError);
        }

        if (_getProcessingCancelledFlag()) {
            logger.info('Processing cancelled by Escape before sending result/pasting.');
            return;
        }

        sendToMain('transcription-result', finalText);
        _sendRecordingStatus('idle');

        if (store.get('settings.autoPaste', true) && !_getProcessingCancelledFlag()) {
           logger.info('Auto-paste enabled, writing to clipboard and simulating paste...');
           clipboard.writeText(finalText);
           if (process.platform === 'darwin') {
              const appleScript = `
                tell application "System Events"
                  keystroke "v" using command down
                end tell
              `;
              exec(`osascript -e '${appleScript}'`, (error) => {
                if (error) {
                  logger.error('Failed to execute paste AppleScript:', error);
                  sendToMain('transcription-error', 'Transcription complete, but failed to paste.');
                } else {
                  logger.info('Paste simulated via AppleScript.');
                }
              });
           } else {
              logger.warn('Auto-paste simulation not implemented for this platform.');
              sendToMain('transcription-error', 'Transcription complete, but auto-paste not supported on this OS.');
           }
        } else if (_getProcessingCancelledFlag()) {
            logger.info('Paste skipped due to cancellation.');
        } else {
            logger.info('Auto-paste disabled, skipping paste action.');
        }

    } catch (error: unknown) {
        if (_getProcessingCancelledFlag()) {
            logger.info('Processing cancelled by Escape during error handling.');
            if (mainProcessRecordingStatus !== 'idle') {
                _sendRecordingStatus('idle');
            }
            return;
        }
        const message = error instanceof Error ? error.message : String(error);
        logger.error('IPC: Transcription failed:', message);
        sendToMain('transcription-error', message);
        _sendRecordingStatus('error');
        throw error;
    }
}

function handleGetAccessibilityStatus() {
    if (process.platform === 'darwin') {
        const isTrusted = systemPreferences.isTrustedAccessibilityClient(false);
        logger.info(`Accessibility Status Check: ${isTrusted ? 'granted' : 'not granted'}`);
        return isTrusted ? 'granted' : 'not-granted';
    }
    logger.warn('Accessibility status check only available on macOS.');
    return 'unavailable';
}

function handleRequestAccessibilityAccess() {
    if (process.platform === 'darwin') {
        logger.info('Checking/Requesting Accessibility access (will prompt user if needed)...');
        const isTrustedNow = systemPreferences.isTrustedAccessibilityClient(true);
        logger.info(`Accessibility status after check/prompt: ${isTrustedNow}`);
        return isTrustedNow;
    }
    logger.warn('Accessibility access request only available on macOS.');
    return false;
}

async function handleGetMediaPermissionStatus(_, mediaType: 'microphone' | 'camera' | 'screen') {
    if (process.platform !== 'darwin') return 'unavailable';
    try {
        const status = systemPreferences.getMediaAccessStatus(mediaType);
        logger.info(`Media Status Check [${mediaType}]: ${status}`);
        return status;
    } catch (error) {
        logger.error(`Error checking media status [${mediaType}]:`, error);
        return 'unavailable';
    }
}

async function handleRequestMediaPermission(_, mediaType: 'microphone' | 'camera') {
    if (process.platform !== 'darwin') return false;
    try {
        logger.info(`Requesting media access [${mediaType}]...`);
        const granted = await systemPreferences.askForMediaAccess(mediaType);
        logger.info(`Media access request result [${mediaType}]: ${granted}`);
        return granted;
    } catch (error) {
        logger.error(`Error requesting media access [${mediaType}]:`, error);
        return false;
    }
}

function handleOpenSettingsURL(_, url: string) {
    if (process.platform === 'darwin' && url.startsWith('x-apple.systempreferences:')) {
        logger.info(`Opening settings URL: ${url}`);
        return shell.openExternal(url);
    }
    logger.warn(`Invalid or unsupported settings URL requested: ${url}`);
    return Promise.resolve();
}

function handleProcessingCancelledSilence() {
    logger.info('IPC: Received notification that processing was cancelled due to silence.');
    _sendRecordingStatus('idle');
}

let mainProcessRecordingStatus: 'idle' | 'recording' | 'processing' | 'error' = 'idle';
export function updateIpcHandlerStatus(status: typeof mainProcessRecordingStatus): void {
    mainProcessRecordingStatus = status;
}

================
File: src/main/modules/shortcutManager.ts
================
import { spawn, ChildProcessWithoutNullStreams } from 'child_process';
import { app } from 'electron';
import path from 'path';
import { logger } from '../logger';

export enum ShortcutState {
    IDLE,
    RECORDING_POTENTIAL_CLICK_OR_HOLD,
    WAITING_FOR_SECOND_CLICK,
    TOGGLE_RECORDING,
}

let currentState: ShortcutState = ShortcutState.IDLE;
let keyDownTime: number | null = null;
let firstClickUpTime: number | null = null;
let holdTimeoutId: NodeJS.Timeout | null = null;
let doubleClickTimeoutId: NodeJS.Timeout | null = null;
let keyMonitorProcess: ChildProcessWithoutNullStreams | null = null;
let currentlyMonitoredKeys: string[] = [];
let ignoreNextUpInToggle = false;

const HOLD_DURATION_THRESHOLD = 500;
const DOUBLE_CLICK_WINDOW = 500;

let _sendRecordingStatus: (status: 'idle' | 'recording' | 'processing' | 'error') => void = () => {};
let _sendRawShortcutAction: (action: string, keyName: string) => void = () => {};
let _startRecording: () => void = () => {};
let _stopRecording: () => void = () => {};
let _cancelRecording: () => void = () => {};
let _notifyProcessingCancelledByEscape: () => void = () => {};

export function initializeShortcutManager(dependencies: {
    sendRecordingStatus: typeof _sendRecordingStatus;
    sendRawShortcutAction: typeof _sendRawShortcutAction;
    startRecording: typeof _startRecording;
    stopRecording: typeof _stopRecording;
    cancelRecording: typeof _cancelRecording;
    notifyProcessingCancelledByEscape: typeof _notifyProcessingCancelledByEscape;
}): void {
    _sendRecordingStatus = dependencies.sendRecordingStatus;
    _sendRawShortcutAction = dependencies.sendRawShortcutAction;
    _startRecording = dependencies.startRecording;
    _stopRecording = dependencies.stopRecording;
    _cancelRecording = dependencies.cancelRecording;
    _notifyProcessingCancelledByEscape = dependencies.notifyProcessingCancelledByEscape;
    logger.info('Shortcut Manager initialized with dependencies.');
}

function resetShortcutState(): void {
    logger.debug("Resetting shortcut state machine to IDLE.");
    currentState = ShortcutState.IDLE;
    keyDownTime = null;
    firstClickUpTime = null;
    if (holdTimeoutId) clearTimeout(holdTimeoutId);
    holdTimeoutId = null;
    if (doubleClickTimeoutId) clearTimeout(doubleClickTimeoutId);
    doubleClickTimeoutId = null;
    ignoreNextUpInToggle = false;
}

function handleKeyEvent(keyName: string, type: 'DOWN' | 'UP'): void {
    const now = Date.now();
    logger.debug(`Key Event: ${keyName}_${type} | Current State: ${ShortcutState[currentState]}`);

    if (type === 'DOWN') {
        if (currentState === ShortcutState.WAITING_FOR_SECOND_CLICK) {
            if (doubleClickTimeoutId) clearTimeout(doubleClickTimeoutId);
            doubleClickTimeoutId = null;

            if (now - (firstClickUpTime ?? 0) < DOUBLE_CLICK_WINDOW) {
                logger.info(`Double Click Detected on ${keyName}. Starting Toggle Recording.`);
                _sendRawShortcutAction('doubleClickStartToggle', keyName);
                currentState = ShortcutState.TOGGLE_RECORDING;
                ignoreNextUpInToggle = true;
                _startRecording();
                _sendRecordingStatus('recording');
            } else {
                logger.debug(`Second click on ${keyName} too late. Treating as new press.`);
                currentState = ShortcutState.RECORDING_POTENTIAL_CLICK_OR_HOLD;
                keyDownTime = now;
                _startRecording();
                _sendRecordingStatus('recording');
            }
        } else if (currentState === ShortcutState.IDLE) {
            logger.debug(`Key Down ${keyName} - Starting immediate recording (Potential Click/Hold).`);
            currentState = ShortcutState.RECORDING_POTENTIAL_CLICK_OR_HOLD;
            keyDownTime = now;
            _startRecording();
            _sendRecordingStatus('recording');
        } else {
            logger.debug(`Ignoring duplicate Key Down ${keyName} in state ${ShortcutState[currentState]}.`);
        }
    } else {
        if (keyDownTime === null && currentState !== ShortcutState.TOGGLE_RECORDING) {
             logger.debug(`Ignoring Key Up ${keyName} - keyDownTime is null or state is unexpected (${ShortcutState[currentState]}).`);
             return;
        }

        const duration = keyDownTime ? now - keyDownTime : 0;
        logger.debug(`Key Up ${keyName}. Duration: ${duration}ms. State: ${ShortcutState[currentState]}`);

        if (currentState === ShortcutState.RECORDING_POTENTIAL_CLICK_OR_HOLD) {
            if (duration < HOLD_DURATION_THRESHOLD) {
                logger.info(`Quick Click Detected on ${keyName}. Cancelling recording.`);
                _sendRawShortcutAction('clickCancel', keyName);
                _cancelRecording();
                logger.debug(`Waiting for potential second click...`);
                currentState = ShortcutState.WAITING_FOR_SECOND_CLICK;
                firstClickUpTime = now;

                if (doubleClickTimeoutId) clearTimeout(doubleClickTimeoutId);
                doubleClickTimeoutId = setTimeout(() => {
                    if (currentState === ShortcutState.WAITING_FOR_SECOND_CLICK) {
                        logger.debug(`Double click timeout expired for ${keyName}. Confirmed single click (ignored). Resetting to IDLE.`);
                        resetShortcutState();
                        _sendRecordingStatus('idle');
                    }
                }, DOUBLE_CLICK_WINDOW);

            } else {
                logger.info(`Hold Released ${keyName}. Stopping PTT Recording.`);
                _sendRawShortcutAction('holdEnd', keyName);
                _stopRecording();
                _sendRecordingStatus('processing');
                resetShortcutState();
            }
        } else if (currentState === ShortcutState.TOGGLE_RECORDING) {
            if (ignoreNextUpInToggle) {
                logger.debug('Ignoring UP event immediately after double-click confirmation.');
                ignoreNextUpInToggle = false;
            } else {
                logger.info(`Stopping Toggle Recording due to UP event.`);
                _sendRawShortcutAction('toggleStop', keyName);
                _stopRecording();
                _sendRecordingStatus('processing');
                resetShortcutState();
            }
        } else {
             logger.debug(`Ignoring Key Up ${keyName} in state ${ShortcutState[currentState]}.`);
        }
    }
}

function handleEscapeKey(): void {
    logger.info('Escape key pressed (from Swift).');
    const currentStatus = mainProcessRecordingStatus;

    if (currentStatus === 'recording') {
        logger.info('🔴 Cancelling active recording via Escape key.');
        _cancelRecording();
        resetShortcutState();
        _sendRecordingStatus('idle');
    } else if (currentStatus === 'processing') {
        logger.info('🟡 Cancelling ongoing processing via Escape key.');
        _notifyProcessingCancelledByEscape();
        resetShortcutState();
        _sendRecordingStatus('idle');
    } else if (currentState === ShortcutState.WAITING_FOR_SECOND_CLICK) {
         logger.info('🟡 Cancelling wait for double-click via Escape key.');
         resetShortcutState();
         _sendRecordingStatus('idle');
    } else {
        logger.debug('Escape pressed, but not in a cancellable state.');
    }
}

export function startKeyMonitor(keysToWatch: string[]): void {
    if (keyMonitorProcess) {
        logger.debug('Stopping existing key monitor before starting new one...');
        stopKeyMonitor();
    }

    if (!keysToWatch || keysToWatch.length === 0) {
        logger.info("No keys specified to monitor. Key monitor not started.");
        currentlyMonitoredKeys = [];
        resetShortcutState();
        return;
    }

    const basePath = app.isPackaged
        ? path.join(process.resourcesPath, 'resources')
        : path.join(app.getAppPath(), 'resources');
    const executablePath = path.join(basePath, 'key-monitor');

    logger.info(`Attempting to start key monitor at: ${executablePath} with keys: ${keysToWatch.join(', ')}`);
    currentlyMonitoredKeys = [...keysToWatch];
    resetShortcutState();

    try {
        keyMonitorProcess = spawn(executablePath, keysToWatch);

        keyMonitorProcess.stdout.on('data', (data: Buffer) => {
            const messages = data.toString().trim().split('\n');
            messages.forEach(message => {
                if (!message) return;

                if (message === 'ESCAPE_DOWN') {
                    handleEscapeKey();
                    return;
                }

                const parts = message.split('_');
                if (parts.length === 2) {
                    const keyName = parts[0];
                    const type = parts[1] as 'DOWN' | 'UP';
                    if ((type === 'DOWN' || type === 'UP') && currentlyMonitoredKeys.includes(keyName) && keyName !== 'ESCAPE') {
                        handleKeyEvent(keyName, type);
                    } else if (!currentlyMonitoredKeys.includes(keyName)) {
                        logger.warn(`Received event for unexpected key: ${keyName}`);
                    }
                } else if (message.startsWith('Monitoring') || message.startsWith('Event tap created')) {
                    logger.debug(`Key Monitor Helper: ${message}`);
                } else {
                     logger.warn(`Received unknown message from key monitor: ${message}`);
                }
            });
        });

        keyMonitorProcess.stderr.on('data', (data: Buffer) => {
            logger.error(`Key Monitor Error: ${data.toString().trim()}`);
        });

        keyMonitorProcess.on('close', (code) => {
            logger.warn(`Key monitor process exited with code ${code}`);
            if (keyMonitorProcess && code !== 0) {
                logger.info('Attempting to restart key monitor...');
                setTimeout(() => startKeyMonitor(currentlyMonitoredKeys), 5000);
            } else {
                keyMonitorProcess = null;
                currentlyMonitoredKeys = [];
                resetShortcutState();
            }
        });

        keyMonitorProcess.on('error', (err) => {
            logger.error('Failed to start key monitor process:', err);
            keyMonitorProcess = null;
            currentlyMonitoredKeys = [];
            resetShortcutState();
        });

    } catch (error) {
        logger.error('Error spawning key monitor process:', error);
        keyMonitorProcess = null;
        currentlyMonitoredKeys = [];
        resetShortcutState();
    }
}

export function stopKeyMonitor(): void {
    if (keyMonitorProcess) {
        logger.info('Stopping key monitor process...');
        keyMonitorProcess.removeAllListeners();
        keyMonitorProcess.kill();
        keyMonitorProcess = null;
        currentlyMonitoredKeys = [];
        resetShortcutState();
        logger.info('Key monitor stopped.');
    }
}

let mainProcessRecordingStatus: 'idle' | 'recording' | 'processing' | 'error' = 'idle';
export function updateMainProcessStatus(status: typeof mainProcessRecordingStatus): void {
    mainProcessRecordingStatus = status;
}

================
File: src/main/modules/windowManager.ts
================
import { app, BrowserWindow, screen, shell } from 'electron';
import { join } from 'path';
import { is } from '@electron-toolkit/utils';
import icon from '../../../resources/icon.png?asset';

let mainWindow: BrowserWindow | null = null;
let widgetWindow: BrowserWindow | null = null;

export function getMainWindow(): BrowserWindow | null {
    return mainWindow;
}

export function getWidgetWindow(): BrowserWindow | null {
    return widgetWindow;
}

export function createMainWindow(): BrowserWindow {
    mainWindow = new BrowserWindow({
        width: 900,
        height: 670,
        show: false,
        autoHideMenuBar: true,
        ...(process.platform === 'linux' ? { icon } : {}),
        webPreferences: {
            preload: join(app.getAppPath(), './out/preload/index.js'),
            sandbox: false,
            contextIsolation: true
        }
    });

    mainWindow.webContents.setWindowOpenHandler((details) => {
        shell.openExternal(details.url);
        return { action: 'deny' };
    });

    const mainWindowPath = join(app.getAppPath(), './out/renderer/index.html');
    const mainWindowUrl = is.dev && process.env['ELECTRON_RENDERER_URL']
        ? process.env['ELECTRON_RENDERER_URL']
        : mainWindowPath;
    if (is.dev) {
        mainWindow.loadURL(mainWindowUrl);
        mainWindow.webContents.openDevTools({ mode: 'detach' });
    } else {
        mainWindow.loadFile(mainWindowPath);
    }

    mainWindow.on('closed', () => {
        mainWindow = null;
    });
    return mainWindow;
}

export function createWidgetWindow(): BrowserWindow | null {
    if (widgetWindow) {
        widgetWindow.focus();
        return widgetWindow;
    }

    const primaryDisplay = screen.getPrimaryDisplay();
    const { width: displayWidth, height: displayHeight } = primaryDisplay.workAreaSize;

    const widgetWidth = 320;
    const widgetHeight = 100;

    const x = Math.round((displayWidth - widgetWidth) / 2);
    const y = Math.round(displayHeight - widgetHeight - 40);

    widgetWindow = new BrowserWindow({
        width: widgetWidth,
        height: widgetHeight,
        x: x,
        y: y,
        show: true,
        frame: false,
        transparent: true,
        alwaysOnTop: true,
        resizable: false,
        movable: false,
        skipTaskbar: true,
        focusable: false,
        webPreferences: {
            preload: join(app.getAppPath(), './out/preload/widget.js'),
            sandbox: false,
            contextIsolation: true,
        }
    });

    setWidgetClickThrough(true);

    let loadPath: string;
    let isUrl = false;

    if (is.dev && process.env['ELECTRON_RENDERER_URL']) {
        const devServerUrl = new URL(process.env['ELECTRON_RENDERER_URL']);
        devServerUrl.pathname = 'widget.html';
        loadPath = devServerUrl.toString();
        isUrl = true;
    } else {
        loadPath = join(app.getAppPath(), './out/renderer/widget.html');
        isUrl = false;
    }

    if (isUrl) {
        widgetWindow.loadURL(loadPath).catch(err => {});
    } else {
        widgetWindow.loadFile(loadPath).catch(err => {});
    }

    widgetWindow.on('closed', () => {
        widgetWindow = null;
    });

    widgetWindow.on('focus', () => {
        focusMainWindow();
    });

    return widgetWindow;
}

export function setWidgetClickThrough(ignore: boolean): void {
    if (widgetWindow && !widgetWindow.isDestroyed()) {
        widgetWindow.setIgnoreMouseEvents(ignore, { forward: ignore });
    }
}

export function focusMainWindow(): void {
    if (mainWindow && !mainWindow.isDestroyed()) {
        mainWindow.focus();
    }
}

export function closeAllWindows(): void {
    if (widgetWindow && !widgetWindow.isDestroyed()) {
        widgetWindow.close();
        widgetWindow = null;
    }
    if (mainWindow && !mainWindow.isDestroyed()) {
        mainWindow.close();
        mainWindow = null;
    }
}

export function sendToWidget(channel: string, ...args: any[]): void {
    if (widgetWindow && !widgetWindow.isDestroyed()) {
        widgetWindow.webContents.send(channel, ...args);
    }
}

export function sendToMain(channel: string, ...args: any[]): void {
    if (mainWindow && !mainWindow.isDestroyed()) {
        mainWindow.webContents.send(channel, ...args);
    }
}

================
File: src/main/transcription/DeepgramService.ts
================
import { createClient } from '@deepgram/sdk';
import { TranscriptionService } from './TranscriptionService';
import store from '../store';
import { logger } from '../logger';

export class DeepgramService implements TranscriptionService {
  private client: ReturnType<typeof createClient> | null = null;

  constructor() {
    this.initializeClient();
    store.onDidChange('transcription', (newValue, oldValue) => {
      if (newValue?.provider === 'deepgram' && newValue?.deepgramApiKey !== oldValue?.deepgramApiKey) {
        logger.info('Transcription settings changed, re-initializing Deepgram client.');
        this.initializeClient();
      } else if (newValue?.provider !== 'deepgram' && this.client !== null) {
        logger.info('Transcription provider changed away from Deepgram, disabling client.');
        this.client = null;
      }
    });
  }

  private initializeClient(): void {
    const provider = store.get('transcription.provider');
    if (provider !== 'deepgram') {
      this.client = null;
      logger.info(`Deepgram provider not selected (current: ${provider}). Deepgram client not initialized.`);
      return;
    }
    const apiKey = store.get('transcription.deepgramApiKey') as string | undefined;
    if (apiKey) {
      try {
        this.client = createClient(apiKey);
        logger.info('Deepgram client initialized with API key.');
      } catch (error) {
        this.client = null;
        logger.error('Error initializing Deepgram client:', error);
      }
    } else {
      this.client = null;
      logger.warn('Deepgram API key not found in settings. Deepgram client not initialized.');
    }
  }

  async transcribe(audioBuffer: Buffer, mimeType: string, language?: string): Promise<string> {
    if (!this.client) {
      logger.error('Deepgram client not initialized. Cannot transcribe.');
      throw new Error('Deepgram client not initialized. API key might be missing.');
    }

    try {
      logger.info(`Sending audio buffer to Deepgram API for transcription... (MIME type: ${mimeType}, Buffer size: ${audioBuffer.length} bytes)`);
      const modelName = store.get('transcription.deepgramModel', 'nova-2');
      logger.info(`Using Deepgram transcription model: ${modelName}`);
      const options: Record<string, any> = {
        model: modelName,
        smart_format: true
      };
      if (language) {
        options.language = language;
      }
      logger.info(`Audio format: ${mimeType}, sending ${audioBuffer.byteLength} bytes to Deepgram`);
      const { result, error } = await this.client.listen.prerecorded.transcribeFile(
        audioBuffer,
        options
      );
      if (error) {
        logger.error('Deepgram API returned an error:', error);
        throw new Error(`Deepgram API error: ${error.message}`);
      }
      if (!result) {
        logger.error('No result returned from Deepgram API');
        throw new Error('No result returned from Deepgram API');
      }
      const transcript = result.results?.channels[0]?.alternatives[0]?.transcript || '';
      if (transcript) {
        logger.info(`Transcription received from Deepgram: "${transcript.substring(0, 50)}${transcript.length > 50 ? '...' : ''}"`);
      } else {
        logger.warn('Deepgram returned empty transcript');
      }
      return transcript;
    } catch (error: unknown) {
      const message = error instanceof Error ? error.message : String(error);
      logger.error('Error during Deepgram transcription:', error);
      throw new Error(`Deepgram transcription failed: ${message}`);
    }
  }
}

================
File: src/main/transcription/LocalWhisperService.ts
================
import { TranscriptionService } from './TranscriptionService'
import store from '../store'
import fs from 'fs'
import os from 'os'
import path from 'path'
import { logger } from '../logger'
import { nodewhisper, IOptions } from 'nodejs-whisper'

interface WhisperOptions {
  outputInCsv?: boolean
  outputInJson?: boolean
  outputInJsonFull?: boolean
  outputInLrc?: boolean
  outputInSrt?: boolean
  outputInText?: boolean
  outputInVtt?: boolean
  outputInWords?: boolean
  translateToEnglish?: boolean
  timestamps_length?: number
  wordTimestamps?: boolean
  splitOnWord?: boolean
  language?: string
}

export const AVAILABLE_LOCAL_MODELS = [
  'tiny', 'tiny.en',
  'base', 'base.en',
  'small', 'small.en',
  'medium', 'medium.en',
  'large-v2', 'large-v3',
  'large-v3-turbo'
];

export class LocalWhisperService implements TranscriptionService {

  constructor() {
    logger.info('LocalWhisperService initialized.');
  }

  private getExtensionFromMimeType(mimeType: string): string | null {
    const mimeMap: { [key: string]: string } = {
      'audio/webm': 'webm',
      'audio/webm;codecs=opus': 'webm',
      'audio/wav': 'wav',
      'audio/mp4': 'mp4',
      'audio/mp3': 'mp3',
      'audio/mpeg': 'mpeg',
      'audio/mpga': 'mpga',
      'audio/aac': 'm4a',
      'audio/x-m4a': 'm4a',
      'audio/m4a': 'm4a',
      'audio/ogg': 'ogg',
      'audio/ogg;codecs=opus': 'ogg',
    };
    const baseMimeType = mimeType.split(';')[0];
    if (mimeMap[baseMimeType]) {
      return mimeMap[baseMimeType];
    }
    logger.warn(`Could not determine file extension for MIME type: ${mimeType}`);
    return 'wav'; 
  }

  async transcribe(audioBuffer: Buffer, mimeType: string, language?: string): Promise<string> {
    const provider = store.get('transcription.provider');
    if (provider !== 'local') {
      logger.error('LocalWhisperService transcribe called when provider is not local.');
      throw new Error('LocalWhisperService called incorrectly.');
    }

    const selectedModel = store.get('transcription.localModelName', 'base.en');
    logger.info(`Using local Whisper model: ${selectedModel}`);

    const extension = this.getExtensionFromMimeType(mimeType) || 'wav';
    const tempFilePath = path.join(os.tmpdir(), `vox-local-audio-${Date.now()}.${extension}`);

    try {
      logger.info(`Writing audio buffer to temporary file for local transcription: ${tempFilePath}`);
      await fs.promises.writeFile(tempFilePath, audioBuffer);

      const whisperOptions: WhisperOptions = {
        outputInText: true,
        translateToEnglish: false,
        wordTimestamps: false,
        splitOnWord: true,
        language: language || 'auto'
      };

      const useGpu = process.platform === 'darwin';
      logger.info(`Local transcription GPU (Metal) usage: ${useGpu}`);

      const options: IOptions = {
        modelName: selectedModel,
        whisperOptions: whisperOptions,
      };

      const loggableOptions = { ...options, logger: undefined, whisperOptions };
      logger.info(`Calling nodejs-whisper with options: ${JSON.stringify(loggableOptions)}`);

      options.whisperOptions!.outputInText = true;
      options.whisperOptions!.outputInSrt = false;
      options.whisperOptions!.outputInVtt = false;
      options.whisperOptions!.outputInJson = false;

      await nodewhisper(tempFilePath, options);

      const outputTxtPath = tempFilePath.replace(`.${extension}`, '.txt');

      if (fs.existsSync(outputTxtPath)) {
        const transcript = await fs.promises.readFile(outputTxtPath, 'utf-8');
        logger.info(`Local transcription successful. Result length: ${transcript.length}`);
        try {
          await fs.promises.unlink(outputTxtPath);
          logger.debug(`Deleted output text file: ${outputTxtPath}`);
        } catch (cleanupError) {
          logger.warn(`Failed to delete output text file ${outputTxtPath}:`, cleanupError);
        }
        return transcript.trim();
      } else {
        logger.error(`Output text file not found after nodejs-whisper execution: ${outputTxtPath}`);
        throw new Error('Local transcription failed: Output file not generated.');
      }

    } catch (error: unknown) {
      const message = error instanceof Error ? error.message : String(error);
      logger.error('Error during local Whisper transcription:', error);
      throw new Error(`Local transcription failed: ${message}`);
    } finally {
      try {
        if (fs.existsSync(tempFilePath)) {
          await fs.promises.unlink(tempFilePath);
          logger.info(`Temporary audio file deleted: ${tempFilePath}`);
        }
      } catch (cleanupError) {
        logger.warn(`Failed to delete temporary audio file ${tempFilePath}:`, cleanupError);
      }
    }
  }

  static async downloadModel(modelName: string): Promise<void> {
      if (!AVAILABLE_LOCAL_MODELS.includes(modelName)) {
          logger.error(`Attempted to download invalid local model: ${modelName}`);
          throw new Error(`Invalid local model name: ${modelName}`);
      }
      logger.info(`Attempting to download local model: ${modelName}...`);
      try {
          const { exec } = await import('child_process');
          const command = `npx nodejs-whisper download ${modelName}`;
          logger.info(`Executing command: ${command}`);

          await new Promise<void>((resolve, reject) => {
              const process = exec(command, (error, stdout, stderr) => {
                  if (error) {
                      logger.error(`Error downloading model ${modelName}: ${error.message}`);
                      logger.error(`stderr: ${stderr}`);
                      reject(error);
                      return;
                  }
                  if (stderr) {
                      logger.warn(`stderr during model download ${modelName}: ${stderr}`);
                  }
                  logger.info(`stdout for model download ${modelName}: ${stdout}`);
                  logger.info(`Successfully downloaded model: ${modelName}`);
                  resolve();
              });

              process.stdout?.on('data', (data) => logger.debug(`[Download ${modelName} stdout]: ${data}`));
              process.stderr?.on('data', (data) => logger.warn(`[Download ${modelName} stderr]: ${data}`));
          });

      } catch (error) {
          logger.error(`Failed to download model ${modelName}:`, error);
          throw error;
      }
  }
}

================
File: src/main/transcription/OpenaiWhisperService.ts
================
import OpenAI from 'openai'
import { TranscriptionService } from './TranscriptionService'
import store from '../store'
import fs from 'fs'
import os from 'os'
import path from 'path'
import { logger } from '../logger'

export class OpenaiWhisperService implements TranscriptionService {
  private openai: OpenAI | null = null

  constructor() {
    this.initializeClient()
    store.onDidChange('transcription', (newValue, oldValue) => {
      if (newValue?.provider === 'openai' && newValue?.openaiApiKey !== oldValue?.openaiApiKey) {
         logger.info('Transcription settings changed, re-initializing OpenAI client.');
         this.initializeClient();
      } else if (newValue?.provider !== 'openai' && this.openai !== null) {
        logger.info('Transcription provider changed away from OpenAI, disabling client.');
        this.openai = null;
      }
    })
  }

  private initializeClient(): void {
    const provider = store.get('transcription.provider');
    if (provider !== 'openai') {
        this.openai = null;
        logger.info(`OpenAI provider not selected (current: ${provider}). OpenAI client not initialized.`);
        return;
    }
    const apiKey = store.get('transcription.openaiApiKey') as string | undefined
    if (apiKey) {
      this.openai = new OpenAI({ apiKey });
      logger.info('OpenAI client initialized with API key.')
    } else {
      this.openai = null;
      logger.warn('OpenAI API key not found in settings. OpenAI client not initialized.')
    }
  }

  private getExtensionFromMimeType(mimeType: string): string | null {
    const mimeMap: { [key: string]: string } = {
      'audio/webm': 'webm',
      'audio/webm;codecs=opus': 'webm',
      'audio/wav': 'wav',
      'audio/mp4': 'mp4',
      'audio/mp3': 'mp3',
      'audio/mpeg': 'mpeg',
      'audio/mpga': 'mpga',
      'audio/aac': 'm4a',
      'audio/x-m4a': 'm4a',
      'audio/m4a': 'm4a',
      'audio/ogg': 'ogg',
      'audio/ogg;codecs=opus': 'ogg',
    };

    const baseMimeType = mimeType.split(';')[0];

    if (mimeMap[baseMimeType]) {
      return mimeMap[baseMimeType];
    }

    logger.warn(`Could not determine file extension for MIME type: ${mimeType}`);
    return null;
  }

  async transcribe(audioBuffer: Buffer, mimeType: string, language?: string): Promise<string> {
    if (!this.openai) {
      logger.error('OpenAI client not initialized. Cannot transcribe.')
      throw new Error('OpenAI client not initialized. API key might be missing.')
    }

    const extension = this.getExtensionFromMimeType(mimeType);
    if (!extension) {
        logger.error(`Unsupported MIME type for OpenAI transcription: ${mimeType}`);
        throw new Error(`Unsupported audio format: ${mimeType}`);
    }

    const tempFilePath = path.join(os.tmpdir(), `vox-audio-${Date.now()}.${extension}`);

    try {
      logger.info(`Writing audio buffer to temporary file: ${tempFilePath}`)
      await fs.promises.writeFile(tempFilePath, audioBuffer)

      logger.info(`Sending audio file to OpenAI Whisper API for transcription...`)
      const model = store.get('transcription.openaiModel', 'gpt-4o-mini-transcribe');
      logger.info(`Using OpenAI transcription model: ${model}`)
      const transcription = await this.openai.audio.transcriptions.create({
        file: fs.createReadStream(tempFilePath),
        model: model,
        language: language
      })
      logger.info(`Transcription received from OpenAI: "${transcription.text}"`)

      return transcription.text
    } catch (error: unknown) {
      const message = error instanceof Error ? error.message : String(error);
      logger.error('Error during OpenAI transcription:', error)
      throw new Error(`OpenAI transcription failed: ${message}`)
    } finally {
      try {
        await fs.promises.unlink(tempFilePath);
        logger.info(`Temporary audio file deleted: ${tempFilePath}`)
      } catch (cleanupError) {
        logger.error(`Failed to delete temporary audio file ${tempFilePath}:`, cleanupError)
      }
    }
  }
}

================
File: src/main/transcription/TranscriptionManager.ts
================
import { TranscriptionService } from './TranscriptionService'
import { OpenaiWhisperService } from './OpenaiWhisperService'
import { DeepgramService } from './DeepgramService'
import { LocalWhisperService } from './LocalWhisperService'
import store from '../store'
import { logger } from '../logger'

type TranscriptionMode = 'openai' | 'deepgram' | 'local'

export class TranscriptionManager {
  private services: Map<TranscriptionMode, TranscriptionService>
  private currentMode: TranscriptionMode | null = null

  constructor() {
    this.services = new Map()
    this.services.set('openai', new OpenaiWhisperService())
    this.services.set('deepgram', new DeepgramService())
    this.services.set('local', new LocalWhisperService())
    this.updateModeFromSettings()
    store.onDidChange('transcription', (newValue, oldValue) => {
      const providerChanged = newValue?.provider !== oldValue?.provider;
      const localModelChanged = newValue?.provider === 'local' && newValue?.localModelName !== oldValue?.localModelName;

      if (providerChanged || localModelChanged) {
          logger.info('Transcription settings changed, updating manager.')
          this.updateModeFromSettings()
       }
    })
  }

  private updateModeFromSettings(): void {
    const modeFromSettings = store.get('transcription.provider') as TranscriptionMode | undefined
    if (modeFromSettings && this.services.has(modeFromSettings)) {
      this.currentMode = modeFromSettings
      logger.info(`TranscriptionManager mode set to: ${this.currentMode}`)
    } else {
      this.currentMode = null
      logger.warn(`TranscriptionManager: Configured mode "${modeFromSettings}" is not available or invalid. No active transcription service.`)
    }
  }

  public async transcribe(audioBuffer: Buffer, mimeType: string, language?: string): Promise<string> {
    if (!this.currentMode) {
      logger.error('TranscriptionManager: No active transcription mode set.')
      throw new Error('No active transcription mode configured.')
    }

    const service = this.services.get(this.currentMode)
    if (!service) {
      logger.error(`TranscriptionManager: Service for mode "${this.currentMode}" not found.`)
      throw new Error(`Internal error: Service for mode ${this.currentMode} not found.`)
    }

    logger.info(`TranscriptionManager: Delegating transcription to ${this.currentMode} service with type ${mimeType}.`)
    try {
      const result = await service.transcribe(audioBuffer, mimeType, language)
      logger.info(`TranscriptionManager: Received result from ${this.currentMode} service.`)
      return result
    } catch (error) {
      logger.error(`TranscriptionManager: Error during transcription via ${this.currentMode} service:`, error)
      throw error
    }
  }
}

================
File: src/main/transcription/TranscriptionService.ts
================
export interface TranscriptionService {
  transcribe(audioBuffer: Buffer, mimeType: string, language?: string): Promise<string>
}

================
File: src/main/historyService.ts
================
import Database from 'better-sqlite3';
import path from 'path';
import { app } from 'electron';
import fs from 'fs';
import { logger } from './logger';
import store, { type EnhancementPrompt } from './store';

export interface HistoryRecord {
  id: string;
  timestamp: number;
  originalText: string;
  renderedPrompt: string | null;
  enhancedText: string | null;
  promptIdUsed: string | null;
  promptNameUsed?: string | null;
}

export interface PaginatedHistory {
  entries: HistoryRecord[];
  totalEntries: number;
  totalPages: number;
  currentPage: number;
}

const dbPath = path.join(app.getPath('userData'), 'transcription_history.db');
let db: Database.Database;

try {
    const dbDir = path.dirname(dbPath);
    if (!fs.existsSync(dbDir)) {
        fs.mkdirSync(dbDir, { recursive: true });
        logger.info(`Created database directory: ${dbDir}`);
    }
} catch (error) {
    logger.error('Failed to create database directory:', error);
}

try {
    db = new Database(dbPath, { verbose: logger.debug });
    logger.info(`Database initialized at: ${dbPath}`);
} catch (error) {
    logger.error('Failed to initialize database:', error);
}

function initializeSchema(): void {
    if (!db) return;
    try {
        db.exec(`
            CREATE TABLE IF NOT EXISTS history (
                id TEXT PRIMARY KEY,
                timestamp INTEGER NOT NULL,
                originalText TEXT NOT NULL,
                renderedPrompt TEXT,
                enhancedText TEXT,
                promptIdUsed TEXT
            );
        `);
        db.exec(`CREATE INDEX IF NOT EXISTS idx_history_timestamp ON history (timestamp);`);

        const columns = db.pragma('table_info(history)');
        const hasRenderedPrompt = columns.some((col: any) => col.name === 'renderedPrompt');
        if (!hasRenderedPrompt) {
            db.exec('ALTER TABLE history ADD COLUMN renderedPrompt TEXT;');
            logger.info('Added renderedPrompt column to history table.');
        }

        logger.info('Database schema initialized successfully.');
    } catch (error) {
        logger.error('Failed to initialize database schema:', error);
    }
}

initializeSchema();

export function addHistoryEntry(entry: Omit<HistoryRecord, 'id' | 'timestamp'>): void {
    if (!db) {
        logger.error('Cannot add history entry: Database not initialized.');
        return;
    }
    const timestamp = Date.now();
    const id = `${timestamp}-${Math.random().toString(36).substring(2, 8)}`;
    const sql = `
        INSERT INTO history (id, timestamp, originalText, renderedPrompt, enhancedText, promptIdUsed)
        VALUES (?, ?, ?, ?, ?, ?)
    `;
    try {
        const stmt = db.prepare(sql);
        stmt.run(
            id,
            timestamp,
            entry.originalText,
            entry.renderedPrompt ?? null,
            entry.enhancedText ?? null,
            entry.promptIdUsed ?? null
        );
        logger.info(`Added history entry: ${id}`);
    } catch (error) {
        logger.error('Failed to add history entry:', error);
    }
}

export function getHistoryEntries(page = 1, pageSize = 10): PaginatedHistory | null {
     if (!db) {
        logger.error('Cannot get history entries: Database not initialized.');
        return null;
    }
    try {
        const countResult = db.prepare('SELECT COUNT(*) as count FROM history').get() as { count: number };
        const totalEntries = countResult.count;
        const totalPages = Math.ceil(totalEntries / pageSize);
        const currentPage = Math.max(1, Math.min(page, totalPages));
        const offset = (currentPage - 1) * pageSize;

        const sql = `
            SELECT * FROM history
            ORDER BY timestamp DESC
            LIMIT ? OFFSET ?
        `;
        const stmt = db.prepare(sql);
        let entries = stmt.all(pageSize, offset) as HistoryRecord[];

        const prompts = store.get('enhancementPrompts', []) as EnhancementPrompt[];
        const promptMap = new Map(prompts.map(p => [p.id, p.name]));

        entries = entries.map(entry => {
            let promptName: string | null = null;
            if (entry.promptIdUsed === 'default') {
                promptName = 'Default Prompt';
            } else if (entry.promptIdUsed) {
                promptName = promptMap.get(entry.promptIdUsed) ?? 'Deleted Prompt';
            }
            return { ...entry, promptNameUsed: promptName };
        });

        logger.info(`Fetched history page ${currentPage}/${totalPages} (${entries.length} entries with prompt names)`);

        return {
            entries,
            totalEntries,
            totalPages,
            currentPage,
        };
    } catch (error) {
        logger.error('Failed to fetch history entries:', error);
        return null;
    }
}

export function deleteHistoryEntry(id: string): boolean {
     if (!db) {
        logger.error('Cannot delete history entry: Database not initialized.');
        return false;
    }
    const sql = 'DELETE FROM history WHERE id = ?';
    try {
        const stmt = db.prepare(sql);
        const result = stmt.run(id);
        logger.info(`Deleted history entry ${id}. Changes: ${result.changes}`);
        return result.changes > 0;
    } catch (error) {
        logger.error(`Failed to delete history entry ${id}:`, error);
        return false;
    }
}

export function clearAllHistory(): boolean {
     if (!db) {
        logger.error('Cannot clear history: Database not initialized.');
        return false;
    }
    const sql = 'DELETE FROM history';
    try {
        const stmt = db.prepare(sql);
        const result = stmt.run();
        logger.info(`Cleared all history entries. Changes: ${result.changes}`);
        return true;
    } catch (error) {
        logger.error('Failed to clear history:', error);
        return false;
    }
}

app.on('before-quit', () => {
    if (db && db.open) {
        logger.info('Closing database connection.');
        db.close();
    }
});

================
File: src/main/index.ts
================
import { app, ipcMain, Tray, Menu, nativeImage } from 'electron';
import path from 'path';
import fs from 'fs';
import { electronApp, optimizer } from '@electron-toolkit/utils';
import store from './store';
import { logger, setupRendererLogger } from './logger';
import { TranscriptionManager } from './transcription/TranscriptionManager';
import { EnhancementManager } from './enhancement/EnhancementManager';
import * as WindowManager from './modules/windowManager';
import * as ShortcutManager from './modules/shortcutManager';
import * as IpcHandlers from './modules/ipcHandlers';

let tray: Tray | null = null;
let transcriptionManager: TranscriptionManager;
let enhancementManager: EnhancementManager;
let processingCancelledByEscape = false;

app.whenReady().then(async () => {
    logger.info('App ready, initializing...');
    electronApp.setAppUserModelId('com.electron');

    if (process.platform === 'darwin') {
      if (app.dock) {
        app.dock.hide();
      }
      logger.info('Dock icon hidden on macOS.');
    }

    setupRendererLogger();

    transcriptionManager = new TranscriptionManager();
    enhancementManager = new EnhancementManager();
    logger.info('Core managers (Transcription, Enhancement) initialized.');

    const sendRecordingStatus = (status: 'idle' | 'recording' | 'processing' | 'error'): void => {
        logger.info(`[Main] Sending status update: ${status}`);
        ShortcutManager.updateMainProcessStatus(status);
        IpcHandlers.updateIpcHandlerStatus(status);
        WindowManager.sendToMain('recording-status', status);
        WindowManager.sendToWidget('widget-status-update', status);
        WindowManager.setWidgetClickThrough(status === 'idle' || status === 'error');
    };

    const sendRawShortcutAction = (action: string, keyName: string): void => {
        WindowManager.sendToMain('shortcutAction', action, keyName);
    };

    const startRecording = (): void => {
        WindowManager.sendToMain('start-recording');
    };

    const stopRecording = (): void => {
        WindowManager.sendToMain('stop-recording');
    };

    const cancelRecording = (): void => {
        WindowManager.sendToMain('cancel-recording');
    };

    const notifyProcessingCancelledByEscape = (): void => {
        processingCancelledByEscape = true;
    };

    const getProcessingCancelledFlag = (): boolean => {
        return processingCancelledByEscape;
    };

    const setProcessingCancelledFlag = (value: boolean): void => {
        processingCancelledByEscape = value;
    };

    ShortcutManager.initializeShortcutManager({
        sendRecordingStatus,
        sendRawShortcutAction,
        startRecording,
        stopRecording,
        cancelRecording,
        notifyProcessingCancelledByEscape,
    });

    IpcHandlers.initializeIpcHandlers({
        transcriptionManager,
        enhancementManager,
        getProcessingCancelledFlag,
        setProcessingCancelledFlag,
        sendRecordingStatus,
    });

    IpcHandlers.setupIpcHandlers();

    WindowManager.createMainWindow();
    WindowManager.createWidgetWindow();

    app.on('browser-window-created', (_, window) => {
        optimizer.watchWindowShortcuts(window);
    });

    if (process.platform === 'darwin') {
        const initialKeys = (store.get('shortcutKeysMapped') as string[] | undefined) || [];
        logger.info('Starting initial key monitor with keys from store:', initialKeys);
        ShortcutManager.startKeyMonitor(initialKeys);
    } else {
        logger.warn('Key monitor helper is only supported on macOS.');
    }

    try {
        const iconPath = app.isPackaged
            ? path.join(process.resourcesPath, 'resources/icon-tray.png')
            : path.join(app.getAppPath(), 'resources/icon-tray.png');

        if (!fs.existsSync(iconPath)) {
            logger.error(`Tray icon not found at: ${iconPath}`);
        } else {
            logger.info(`Loading tray icon from: ${iconPath}`);
            const icon = nativeImage.createFromPath(iconPath);
            if (process.platform === 'darwin') {
                icon.setTemplateImage(true);
            }

            tray = new Tray(icon);

            const contextMenu = Menu.buildFromTemplate([
                {
                    label: 'Show Settings',
                    click: () => {
                        let win = WindowManager.getMainWindow();
                        if (!win || win.isDestroyed()) {
                            win = WindowManager.createMainWindow();
                            win.once('ready-to-show', () => {
                                win?.show();
                                win?.focus();
                            });
                        } else {
                            win.show();
                            win.focus();
                        }
                    }
                },
                { type: 'separator' },
                {
                    label: 'Quit Vox Transcriber',
                    click: () => {
                        app.quit();
                    }
                }
            ]);

            tray.setToolTip('Vox Transcriber');
            tray.setContextMenu(contextMenu);

            if (process.platform === 'darwin') {
                tray.on('click', () => {
                    const win = WindowManager.getMainWindow();
                    if (win && !win.isDestroyed()) {
                        if (win.isVisible() && win.isFocused()) {
                            win.hide();
                        } else {
                            win.show();
                            win.focus();
                        }
                    } else {
                        const newWin = WindowManager.createMainWindow();
                        newWin.once('ready-to-show', () => {
                            newWin?.show();
                            newWin?.focus();
                        });
                    }
                });
            }
        }
    } catch (error) {
        logger.error('Failed to create Tray icon:', error);
    }

    app.on('activate', () => {
        let win = WindowManager.getMainWindow();
        if (!win || win.isDestroyed()) {
            win = WindowManager.createMainWindow();
            win.once('ready-to-show', () => {
                win?.show();
                win?.focus();
            });
        } else {
            win.show();
            win.focus();
        }
        if (WindowManager.getWidgetWindow() === null) {
            WindowManager.createWidgetWindow();
        }
    });

    logger.info('App initialization complete.');

}).catch(error => {
    logger.error('Error during app initialization:', error);
    app.quit();
});

app.on('window-all-closed', () => {
    if (process.platform !== 'darwin') {
        app.quit();
    }
});

app.on('before-quit', () => {
    ShortcutManager.stopKeyMonitor();
});

app.on('will-quit', () => {
    ShortcutManager.stopKeyMonitor();
});

================
File: src/main/logger.ts
================
import { ipcMain } from 'electron';
import log from 'electron-log';

log.transports.file.level = 'info';
log.transports.console.level = 'debug';
log.initialize();

export function mainLog(level: 'info' | 'warn' | 'error' | 'debug' | 'verbose', message: string, ...args: unknown[]): void {
  log[level](`[Main] ${message}`, ...args);
}

export function setupRendererLogger(): void {
  ipcMain.on('logFromRenderer', (_event, level: string, message: string, ...args: unknown[]) => {
    const validLevels = ['info', 'warn', 'error', 'debug', 'verbose'];
    const logLevel = validLevels.includes(level) ? level as 'info' | 'warn' | 'error' | 'debug' | 'verbose' : 'info';
    log[logLevel](`[Renderer] ${message}`, ...args);
  });
  mainLog('info', 'Renderer logger initialized via IPC.');
}

export const logger = {
    info: (message: string, ...args: unknown[]): void => mainLog('info', message, ...args),
    warn: (message: string, ...args: unknown[]): void => mainLog('warn', message, ...args),
    error: (message: string, ...args: unknown[]): void => mainLog('error', message, ...args),
    debug: (message: string, ...args: unknown[]): void => mainLog('debug', message, ...args),
    verbose: (message: string, ...args: unknown[]): void => mainLog('verbose', message, ...args),
};

================
File: src/main/store.ts
================
import Store from 'electron-store'

interface DictionarySettings {
  words: string[]
}

interface TranscriptionSettings {
  provider: 'openai' | 'deepgram' | 'local';
  openaiApiKey: string;
  openaiModel: 'gpt-4o-mini-transcribe' | 'gpt-4o-transcribe';
  deepgramApiKey: string;
  deepgramModel: 'nova-3' | 'enhanced' | 'whisper-large';
  localModelName: string;
}

interface EnhancementSettings {
  enabled: boolean;
  provider: 'openai' | 'gemini' | 'custom';
  openaiApiKey: string;
  openaiModel: 'gpt-4.1' | 'gpt-4.1-mini';
  openaiBaseUrl?: string;
  geminiApiKey: string;
  geminiModel: 'gemini-2.0-flash' | 'gemini-2.5-flash' | 'gemini-2.0-flash-lite';
  customApiKey: string;
  customModelName: string;
  customBaseUrl?: string;
  activePromptId: string;
  useTranscript: boolean;
  useContextScreen: boolean;
  useContextInputField: boolean;
  useContextClipboard: boolean;
  useDictionaryWordList: boolean;
}

interface EnhancementPrompt {
  id: string;
  name: string;
  template: string;
}

interface ShortcutSettings {
  pushToTalk: string
  toggleRecording: string
}

interface HistoryEntry {
  id: string
  text: string
  timestamp: number
  duration: number
  enhanced: boolean
}

interface StoreSchema {
  settings: {
    theme: 'cupcake' | 'dark';
    autoPaste: boolean;
  }
  dictionary: DictionarySettings
  transcription: TranscriptionSettings
  enhancements: EnhancementSettings;
  enhancementPrompts: EnhancementPrompt[];
  shortcuts: ShortcutSettings;
  history: HistoryEntry[];
}

const store = new Store<StoreSchema>({
  defaults: {
    settings: {
      theme: 'cupcake',
      autoPaste: true
    },
    dictionary: {
      words: []
    },
    transcription: {
      provider: 'openai',
      openaiApiKey: '',
      openaiModel: 'gpt-4o-mini-transcribe',
      deepgramApiKey: '',
      deepgramModel: 'nova-3',
      localModelName: 'base'
    },
    enhancements: {
      enabled: false,
      provider: 'openai',
      openaiApiKey: '',
      openaiModel: 'gpt-4.1-mini',
      openaiBaseUrl: '',
      geminiApiKey: '',
      geminiModel: 'gemini-2.0-flash',
      customApiKey: '',
      customModelName: '',
      customBaseUrl: '',
      activePromptId: 'default',
      useTranscript: true,
      useContextScreen: false,
      useContextInputField: false,
      useContextClipboard: false,
      useDictionaryWordList: false
    },
    enhancementPrompts: [],
    shortcuts: {
        pushToTalk: 'CommandOrControl+Shift+Space',
        toggleRecording: 'CommandOrControl+Shift+R'
    },
    history: []
  }
})

export default store

export type { EnhancementSettings, EnhancementPrompt };

================
File: src/preload/index.d.ts
================
import { ElectronAPI } from '@electron-toolkit/preload';

interface HistoryRecord {
  id: string;
  timestamp: number;
  originalText: string;
  enhancedText: string | null;
  promptIdUsed: string | null;
  promptNameUsed: string | null;
}

interface PaginatedHistory {
  entries: HistoryRecord[];
  totalEntries: number;
  totalPages: number;
  currentPage: number;
}

declare global {
  interface Window {
    electron: ElectronAPI
    api: {
      getStoreValue: (key: string) => Promise<unknown>
      setStoreValue: (key: string, value: unknown) => Promise<void>,
      updateMonitoredKeys: (keys: string[]) => Promise<void>,
      onShortcutAction: (callback: (action: string, keyName: string) => void) => (() => void),
      onRecordingStateUpdate: (callback: (state: { isRecording: boolean; isToggleMode: boolean }) => void) => (() => void),
      log: (level: 'info' | 'warn' | 'error' | 'debug' | 'verbose', message: string, ...args: unknown[]) => void,
      getAccessibilityStatus: () => Promise<'granted' | 'not-granted' | 'unavailable'>,
      requestAccessibilityAccess: () => Promise<boolean>,
      getMediaPermissionStatus: (mediaType: 'microphone' | 'camera' | 'screen') => Promise<'not-determined' | 'granted' | 'denied' | 'restricted' | 'unknown' | 'unavailable'>,
      requestMediaPermission: (mediaType: 'microphone' | 'camera') => Promise<boolean>,
      openSettingsURL: (url: string) => Promise<void>,
      onStartRecording: (callback: () => void) => (() => void),
      onStopRecording: (callback: () => void) => (() => void),
      onCancelRecording: (callback: () => void) => (() => void),
      updateRecordingStatus: (status: 'idle' | 'recording' | 'processing' | 'error') => void,
      transcribeAudio: (audio: { audioData: ArrayBuffer, mimeType: string }) => Promise<void>,
      onTranscriptionResult: (callback: (text: string) => void) => (() => void),
      onTranscriptionError: (callback: (error: string) => void) => (() => void),
      onRecordingStatus: (callback: (status: 'idle' | 'recording' | 'processing' | 'error') => void) => (() => void),
      getHistory: (page?: number, pageSize?: number) => Promise<PaginatedHistory | null>,
      deleteHistoryEntry: (id: string) => Promise<boolean>,
      clearAllHistory: () => Promise<boolean>,
      notifySilenceCancellation: () => void,
      notifyRecorderStarted: () => void;
      getDefaultPromptContent: () => Promise<string>
    }
  }
}

================
File: src/preload/index.ts
================
import { contextBridge, ipcRenderer } from 'electron'
import { electronAPI } from '@electron-toolkit/preload'

const api = {
  getStoreValue: (key: string): Promise<unknown> => ipcRenderer.invoke('getStoreValue', key),
  setStoreValue: (key: string, value: unknown): Promise<void> =>
    ipcRenderer.invoke('setStoreValue', key, value),
  updateMonitoredKeys: (keys: string[]): Promise<void> => ipcRenderer.invoke('updateMonitoredKeys', keys),
  onShortcutAction: (callback: (action: string, key: string) => void) => {
    const handler = (_event: Electron.IpcRendererEvent, action: string, key: string): void => callback(action, key);
    ipcRenderer.on('shortcutAction', handler);
    return (): void => {
      ipcRenderer.removeListener('shortcutAction', handler);
    };
  },
  onRecordingStateUpdate: (callback: (state: { isRecording: boolean; isToggleMode: boolean }) => void) => {
      const handler = (_event: Electron.IpcRendererEvent, state: { isRecording: boolean; isToggleMode: boolean }): void => callback(state);
      ipcRenderer.on('recordingStateUpdate', handler);
      return (): void => {
          ipcRenderer.removeListener('recordingStateUpdate', handler);
      };
  },
  log: (level: string, message: string, ...args: unknown[]): void => {
      ipcRenderer.send('logFromRenderer', level, message, ...args);
  },
  getAccessibilityStatus: (): Promise<'granted' | 'not-granted' | 'unavailable'> => ipcRenderer.invoke('getAccessibilityStatus'),
  requestAccessibilityAccess: (): Promise<boolean> => ipcRenderer.invoke('requestAccessibilityAccess'),
  getMediaPermissionStatus: (mediaType: 'microphone' | 'camera' | 'screen'): Promise<'not-determined' | 'granted' | 'denied' | 'restricted' | 'unknown' | 'unavailable'> => ipcRenderer.invoke('getMediaPermissionStatus', mediaType),
  requestMediaPermission: (mediaType: 'microphone' | 'camera'): Promise<boolean> => ipcRenderer.invoke('requestMediaPermission', mediaType),
  openSettingsURL: (url: string): Promise<void> => ipcRenderer.invoke('openSettingsURL', url),
  onStartRecording: (callback: () => void) => {
    const handler = (): void => callback();
    ipcRenderer.on('start-recording', handler);
    return (): void => {
      ipcRenderer.removeListener('start-recording', handler);
    };
  },
  onCancelRecording: (callback: () => void) => {
    const handler = (): void => callback();
    ipcRenderer.on('cancel-recording', handler);
    return (): void => {
      ipcRenderer.removeListener('cancel-recording', handler);
    };
  },
  onStopRecording: (callback: () => void) => {
    const handler = (): void => callback();
    ipcRenderer.on('stop-recording', handler);
    return (): void => {
      ipcRenderer.removeListener('stop-recording', handler);
    };
  },
  updateRecordingStatus: (status: 'idle' | 'recording' | 'processing' | 'error'): void => {
    ipcRenderer.send('update-recording-status', status);
  },
  transcribeAudio: (audio: { audioData: ArrayBuffer, mimeType: string }): Promise<void> => ipcRenderer.invoke('transcribe-audio', audio),
  onTranscriptionResult: (callback: (text: string) => void) => {
    const handler = (_event: Electron.IpcRendererEvent, text: string): void => callback(text);
    ipcRenderer.on('transcription-result', handler);
    return (): void => {
      ipcRenderer.removeListener('transcription-result', handler);
    };
  },
  onTranscriptionError: (callback: (error: string) => void) => {
    const handler = (_event: Electron.IpcRendererEvent, error: string): void => callback(error);
    ipcRenderer.on('transcription-error', handler);
    return (): void => {
      ipcRenderer.removeListener('transcription-error', handler);
    };
  },
  onRecordingStatus: (callback: (status: 'idle' | 'recording' | 'processing' | 'error') => void) => {
    const handler = (_event: Electron.IpcRendererEvent, status: 'idle' | 'recording' | 'processing' | 'error'): void => callback(status);
    ipcRenderer.on('recording-status', handler);
    return (): void => {
      ipcRenderer.removeListener('recording-status', handler);
    };
  },
  getHistory: (page?: number, pageSize?: number): Promise<any | null> => ipcRenderer.invoke('getHistory', page, pageSize),
  deleteHistoryEntry: (id: string): Promise<boolean> => ipcRenderer.invoke('deleteHistoryEntry', id),
  clearAllHistory: (): Promise<boolean> => ipcRenderer.invoke('clearAllHistory'),
  notifySilenceCancellation: (): void => ipcRenderer.send('processing-cancelled-silence'),
  getDefaultPromptContent: (): Promise<string> => ipcRenderer.invoke('getDefaultPromptContent'),
  notifyRecorderStarted: (): void => ipcRenderer.send('recorder-actually-started'),
};

if (process.contextIsolated) {
  try {
    contextBridge.exposeInMainWorld('electron', electronAPI)
    contextBridge.exposeInMainWorld('api', api)
  } catch (error) {
    console.error(error)
  }
} else {
  window.electron = electronAPI
  window.api = api
}

================
File: src/preload/widget.d.ts
================
// Define the structure of the API exposed by preload/widget.ts
export interface WidgetAPI {
  // Main -> Widget: Receive status updates
  onStatusUpdate: (callback: (status: 'idle' | 'recording' | 'processing' | 'error') => void) => () => void;
  stopRecording: () => void;
      onRecorderStarted: (callback: () => void) => () => void; // Main -> Widget
}

// Augment the global Window interface
declare global {
  interface Window {
    widgetApi: WidgetAPI;
  }
}

// Export an empty object to satisfy ES module requirements if needed by tsconfig
export {};

================
File: src/preload/widget.ts
================
import { contextBridge, ipcRenderer } from 'electron';

const widgetApi = {
  onStatusUpdate: (callback: (status: 'idle' | 'recording' | 'processing' | 'error') => void) => {
    const handler = (_event: Electron.IpcRendererEvent, status: 'idle' | 'recording' | 'processing' | 'error'): void => {
      callback(status);
    };
    ipcRenderer.on('widget-status-update', handler);
    return (): void => {
      ipcRenderer.removeListener('widget-status-update', handler);
    };
  },
  onRecorderStarted: (callback: () => void) => {
    const handler = (): void => callback();
    ipcRenderer.on('widget-recorder-started', handler);
    return (): void => {
      ipcRenderer.removeListener('widget-recorder-started', handler);
    };
  },
  stopRecording: () => {
    ipcRenderer.send('widget-stop-recording');
  }
};

try {
  contextBridge.exposeInMainWorld('widgetApi', widgetApi);
} catch (error) {
  console.error('Failed to expose Widget API:', error);
}

================
File: src/renderer/src/assets/main.css
================
@import 'remixicon/fonts/remixicon.css';

/* Disable text selection globally for a more native app feel */
body, html {
  -webkit-user-select: none; /* Safari */
  -ms-user-select: none; /* IE 10 and IE 11 */
  user-select: none; /* Standard syntax */
}

/* Allow text selection in input fields and textareas */
input,
textarea {
  -webkit-user-select: text; /* Safari */
  -ms-user-select: text; /* IE 10 and IE 11 */
  user-select: text; /* Standard syntax */
}
@import "tailwindcss";

@plugin "daisyui" {
  themes: caramellatte --default;
}

:root[data-theme="caramellatte"] {
  background-color: transparent;
}

================
File: src/renderer/src/assets/widget.css
================
@import 'remixicon/fonts/remixicon.css';

/* Disable text selection globally for a more native app feel */
body, html {
  -webkit-user-select: none; /* Safari */
  -ms-user-select: none; /* IE 10 and IE 11 */
  user-select: none; /* Standard syntax */
}

@import "tailwindcss";

================
File: src/renderer/src/components/layout/AppLayout.svelte
================
<script lang="ts">
  import StatusIndicator from './StatusIndicator.svelte';

  export let activePage = 'dashboard';

  const navItems = [
    { id: 'dashboard', label: 'Dashboard', icon: 'dashboard-3' },
    { id: 'shortcuts', label: 'Shortcuts', icon: 'command' },
    { id: 'transcription', label: 'Transcription', icon: 'mic' },
    { id: 'enhancements', label: 'Enhancements', icon: 'sparkling' },
    { id: 'dictionary', label: 'Dictionary', icon: 'book' },
    { id: 'permissions', label: 'Permissions', icon: 'shield-check' },
    { id: 'history', label: 'History', icon: 'time' }
  ];
</script>

<div class="flex min-h-screen">
  <aside class="bg-base-200 w-64 h-screen flex flex-col sticky top-0">
    <div class="px-4 py-6">
      <h1 class="text-2xl font-bold">🎤✨</h1>
    </div>

    <ul class="menu menu-lg p-2 pt-0 flex-1 overflow-y-auto">
      {#each navItems as item}
        <li>
          <a
            href="#{item.id}"
            class="{activePage === item.id ? 'active' : ''}"
            on:click={(): void => { activePage = item.id; }}
          >
            <span class="flex items-center text-base">
              <i class="ri-{item.icon}-line mr-3"></i>
              {item.label}
            </span>
          </a>
        </li>
      {/each}
    </ul>

    <div class="mt-auto mb-0">
      <StatusIndicator />
    </div>

    <div class="p-4 text-xs opacity-70">
      <p>Vox Transcriber v1.0.0</p>
    </div>
  </aside>

  <main class="flex-1 overflow-y-auto">
    <div class="p-4 md:p-6">
      <slot />
    </div>
  </main>
</div>

================
File: src/renderer/src/components/layout/StatusIndicator.svelte
================
<script lang="ts">
  import { recordingStatus, transcriptionResult, transcriptionError } from '../../lib/audioRecorder';
  import { onDestroy } from 'svelte';

  let statusText = 'Ready';
  let iconClass = 'ri-mic-line'; // Default icon
  let indicatorClass = 'bg-base-content/20'; // Default background
  let showResultTimeout: NodeJS.Timeout | null = null;

  const statusUnsubscribe = recordingStatus.subscribe(status => {
    clearTimeoutIfActive();
    switch (status) {
      case 'recording':
        statusText = 'Recording';
        iconClass = 'ri-record-circle-fill text-error animate-pulse'; // Pulsing red circle
        indicatorClass = 'bg-error/20';
        break;
      case 'processing':
        statusText = 'Processing';
        iconClass = 'ri-loader-4-line animate-spin'; // Spinner
        indicatorClass = 'bg-info/20';
        break;
      case 'error':
        statusText = $transcriptionError || 'Error'; // Show specific error if available
        iconClass = 'ri-error-warning-fill text-error'; // Error icon
        indicatorClass = 'bg-error/20';
        // Keep error visible for a while
        showResultTimeout = setTimeout(() => {
            if ($recordingStatus === 'error') { // Only reset if still in error state
                 recordingStatus.set('idle'); // Reset to idle after timeout
            }
        }, 5000);
        break;
      case 'idle':
      default:
        // Check if there's a recent result or error to display briefly
        if ($transcriptionResult) {
            statusText = 'Done';
            iconClass = 'ri-check-line text-success'; // Checkmark
            indicatorClass = 'bg-success/20';
            // Show result briefly then return to idle
            showResultTimeout = setTimeout(() => {
                 if ($recordingStatus === 'idle') { // Avoid race conditions
                    resetToIdle();
                 }
            }, 3000);
        } else {
             resetToIdle(); // Go directly to idle if no result/error
        }
        break;
    }
  });

  // Also watch transcriptionResult and transcriptionError directly
  // in case they update while status is already 'idle' (e.g., paste error)
  const resultUnsubscribe = transcriptionResult.subscribe(result => {
      if (result && $recordingStatus === 'idle') {
          clearTimeoutIfActive();
          statusText = 'Done';
          iconClass = 'ri-check-line text-success';
          indicatorClass = 'bg-success/20';
          showResultTimeout = setTimeout(resetToIdle, 3000);
      }
  });

  const errorUnsubscribe = transcriptionError.subscribe(error => {
      if (error && $recordingStatus !== 'error') { // Don't override if already in error state
          clearTimeoutIfActive();
          statusText = error;
          iconClass = 'ri-error-warning-fill text-error';
          indicatorClass = 'bg-error/20';
          showResultTimeout = setTimeout(() => {
              if ($recordingStatus !== 'recording' && $recordingStatus !== 'processing') {
                  recordingStatus.set('idle'); // Reset only if not actively recording/processing
              }
          }, 5000);
      }
  });


  function resetToIdle() {
      statusText = 'Ready';
      iconClass = 'ri-mic-line';
      indicatorClass = 'bg-base-content/20';
      // Clear results/errors from stores when truly idle? Optional.
      // transcriptionResult.set(null);
      // transcriptionError.set(null);
  }

  function clearTimeoutIfActive() {
      if (showResultTimeout) {
          clearTimeout(showResultTimeout);
          showResultTimeout = null;
      }
  }

  onDestroy(() => {
    statusUnsubscribe();
    resultUnsubscribe();
    errorUnsubscribe();
    clearTimeoutIfActive();
  });

</script>

<div class="px-4 py-2 mb-2 flex items-center space-x-2 rounded-md {indicatorClass}">
  <i class="{iconClass} text-lg"></i>
  <span class="text-sm font-medium truncate" title={$transcriptionError ?? statusText}>
    {statusText}
  </span>
</div>

================
File: src/renderer/src/components/settings/Dashboard.svelte
================
<script lang="ts">
  // Removed incorrect store import

  // Status is usually managed by the main process
  let status = {
    isRecording: false,
    isInitialized: true,
    transcriptionBackend: "Local Whisper",
    enhancementEnabled: false,
    lastTranscription: null as string | null
  };

  // Example transcriptions for demo
  const recentTranscriptions = [
    { text: "This is a test transcription to demonstrate the UI.", timestamp: Date.now() - 60000, enhanced: false },
    { text: "Vox transcriber is designed to help you convert speech to text quickly.", timestamp: Date.now() - 600000, enhanced: true }
  ];
</script>

<div class="p-4">
  <h2 class="text-2xl font-bold mb-6">Dashboard</h2>
  
  <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
    <!-- Status Card -->
    <div class="card bg-base-100 shadow-md">
      <div class="card-body">
        <h3 class="card-title">System Status</h3>

        <div class="divider my-1"></div>
        
        <div class="grid grid-cols-2 gap-2">
          <div class="font-semibold">Recording:</div>
          <div class="flex items-center">
            <span class="{status.isRecording ? 'bg-red-500' : 'bg-gray-400'} rounded-full w-2 h-2 mr-2"></span>
            {status.isRecording ? 'Active' : 'Inactive'}
          </div>
          
          <div class="font-semibold">Whisper Engine:</div>
          <div class="flex items-center">
            <span class="{status.isInitialized ? 'bg-green-500' : 'bg-yellow-500'} rounded-full w-2 h-2 mr-2"></span>
            {status.isInitialized ? 'Ready' : 'Initializing...'}
          </div>
          
          <div class="font-semibold">Backend:</div>
          <div>{status.transcriptionBackend}</div>
          
          <div class="font-semibold">Enhancement:</div>
          <div>{status.enhancementEnabled ? 'Enabled' : 'Disabled'}</div>
        </div>
      </div>
    </div>
    
    <!-- Shortcuts Card -->
    <div class="card bg-base-100 shadow-md">
      <div class="card-body">
        <h3 class="card-title">Quick Actions</h3>
        <div class="divider my-1"></div>
        
        <div class="flex flex-col gap-3">
          <button class="btn btn-primary">Test Microphone</button>
          <button class="btn btn-secondary">Test Transcription</button>
          <button class="btn">Configure Permissions</button>
        </div>
      </div>
    </div>
    
    <!-- Recent Transcriptions -->
    <div class="card bg-base-100 shadow-md md:col-span-2">
      <div class="card-body">
        <h3 class="card-title">Recent Transcriptions</h3>
        <div class="divider my-1"></div>
        
        {#if recentTranscriptions.length > 0}
          <div class="flex flex-col gap-4">
            {#each recentTranscriptions as transcription}
              <div class="bg-base-200 p-3 rounded-lg">
                <p class="text-sm mb-2">{new Date(transcription.timestamp).toLocaleString()}</p>
                <p class="text-lg">{transcription.text}</p>
                {#if transcription.enhanced}
                  <span class="badge badge-accent mt-2">Enhanced</span>
                {/if}
              </div>
            {/each}
          </div>
        {:else}
          <p class="text-center py-4 text-base-content/70">No recent transcriptions</p>
        {/if}
        
        <div class="card-actions justify-end mt-2">
          <a href="#history" class="btn btn-sm btn-outline">View All History</a>
        </div>
      </div>
    </div>
  </div>
</div>

================
File: src/renderer/src/components/settings/Dictionary.svelte
================
<script lang="ts">
  import { onMount, tick } from 'svelte'; // Add tick
  import { writable, get } from 'svelte/store'; // Import writable/get

  // Define the type locally or import from a shared types file if available
  interface DictionarySettings {
    words: string[];
  }

  // Use writable store for dictionary settings
  const dictionarySettings = writable<DictionarySettings>({ words: [] });

  // New word to be added
  let newWord = '';

  onMount(async () => {
    const storedSettings = await window.api.getStoreValue('dictionary') as DictionarySettings | undefined;
    if (storedSettings) {
      dictionarySettings.set({ ...storedSettings }); // Use set for writable store
    }
    // Mark loading as complete *after* initial load
    isLoading = false;
  });

  // Debounced save function
  let saveTimeout: NodeJS.Timeout | null = null;
  const saveSettings = (currentSettings: DictionarySettings) => {
      if (isLoading) return; // Prevent saving during initial load
      if (saveTimeout) clearTimeout(saveTimeout);
      saveTimeout = setTimeout(async () => {
          try {
              await window.api.setStoreValue('dictionary', currentSettings);
              window.api.log('info', 'Dictionary settings auto-saved.');
          } catch (error) {
              window.api.log('error', 'Failed to auto-save dictionary settings:', error);
          }
      }, 500); // Debounce 500ms
  };

  // Reactive statement to save when words array changes
  $: if ($dictionarySettings?.words) {
      // Check isLoading to prevent saving on initial mount
      if (!isLoading) {
          saveSettings($dictionarySettings);
      }
  }

  // Add a new word to dictionary
  const addWord = (): void => {
    if (newWord.trim() === '') return;

    // Check if word already exists using get() for current value
    if (!get(dictionarySettings).words.includes(newWord.trim())) {
      // Update the store using update()
      dictionarySettings.update(settings => ({
          ...settings,
          words: [...settings.words, newWord.trim()]
      }));
      newWord = '';
    }
  };

  // Remove a word from dictionary using update()
  const removeWord = (wordToRemove: string): void => {
    dictionarySettings.update(settings => ({
        ...settings,
        words: settings.words.filter(w => w !== wordToRemove)
    }));
  };

  // UI feedback
  // let saveSuccess = false; // Removed
  let isLoading = true; // Added loading flag
</script>

<div class="p-4">
  <h2 class="text-2xl font-bold mb-6">Custom Dictionary</h2>

  <div class="bg-base-100 max-w-xl">
      <p class="text-sm opacity-70 mb-4">
        Add custom words, technical terms, or names to improve transcription accuracy. This only works if you enable enhancements.
      </p>

      <div class="form-control">
        <div class="input-group">
          <input
            type="text"
            class="input input-bordered flex-1"
            placeholder="Enter a custom word..."
            bind:value={newWord}
            on:keypress={(e): void => { if (e.key === 'Enter') addWord(); }}
          />
          <button class="btn btn-primary" on:click={addWord}>
            Add Word
          </button>
        </div>
      </div>

      <div class="mt-6">
        <h4 class="font-semibold mb-2">Current Dictionary</h4>

        {#if $dictionarySettings.words.length === 0}
          <div class="bg-base-200 p-4 text-center rounded-lg">
            <p class="opacity-60">Your custom dictionary is empty</p>
            <p class="text-sm mt-1 opacity-50">Add words above to improve transcription accuracy</p>
          </div>
        {:else}
          <div class="flex flex-wrap gap-2">
            {#each $dictionarySettings.words as word}
              <div class="badge badge-lg flex gap-1 p-1 pl-3">
                <span>{word}</span>
                <button
                  class="btn btn-xs btn-ghost btn-circle"
                  aria-label={`Remove word ${word}`}
                  on:click={(): void => { removeWord(word); }}
                >
                  <svg xmlns="http://www.w3.org/2000/svg" class="h-3 w-3" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" />
                  </svg>
                </button>
              </div>
            {/each}
          </div>
        {/if}

        {#if $dictionarySettings.words.length > 0}
          <button
            class="btn btn-xs btn-outline mt-4"
            on:click={() => dictionarySettings.update(s => ({ ...s, words: [] }))}
          >
            Clear All
          </button>
        {/if}
      </div>

      <div class="bg-base-200 rounded-md p-3 mt-6">
        <h4 class="font-semibold mb-1">How it works:</h4>
        <p class="text-sm opacity-80">
          Words added to your custom dictionary will be given higher priority during transcription.
          This is especially useful for technical terms, uncommon names, or domain-specific jargon
          that might otherwise be misinterpreted.
        </p>
      </div>

      <!-- Removed Save Success Alert -->

      <!-- Removed Save Button -->
    </div>
  </div>

================
File: src/renderer/src/components/settings/Enhancements.svelte
================
<script lang="ts">
  import { onMount } from 'svelte';
  import { v4 as uuidv4 } from 'uuid';
  import { writable, get } from 'svelte/store';

  interface EnhancementSettings {
    enabled: boolean;
    provider: 'openai' | 'gemini' | 'custom';
    openaiApiKey: string;
    openaiModel: 'gpt-4.1' | 'gpt-4.1-mini';
    openaiBaseUrl?: string;
    geminiApiKey: string;
    geminiModel: 'gemini-2.0-flash' | 'gemini-2.5-flash' | 'gemini-2.0-flash-lite';
    customApiKey: string;
    customModelName: string;
    customBaseUrl?: string;
    activePromptId: string;
    useTranscript: boolean;
    useContextScreen: boolean;
    useContextInputField: boolean;
    useContextClipboard: boolean;
    useDictionaryWordList: boolean;
  }

  interface EnhancementPrompt {
    id: string;
    name: string;
    template: string;
  }

  const settings = writable<EnhancementSettings>({
    enabled: false,
    provider: 'openai',
    openaiApiKey: '',
    openaiModel: 'gpt-4.1-mini',
    openaiBaseUrl: '',
    geminiApiKey: '',
    geminiModel: 'gemini-2.0-flash',
    customApiKey: '',
    customModelName: '',
    customBaseUrl: '',
    activePromptId: 'default',
    useTranscript: true,
    useContextScreen: false,
    useContextInputField: false,
    useContextClipboard: false,
    useDictionaryWordList: false
  });

  let isLoading = true;
  const prompts = writable<EnhancementPrompt[]>([]);
  let newPromptName = '';
  let newPromptTemplate = '';
  let showAddPrompt = false;
  let showPromptModal = false;
  let modalMode: 'view' | 'edit' | 'add' = 'add';
  let currentPrompt: EnhancementPrompt | { id: 'default', name: string, template: string } | null = null;
  let editPromptName = '';
  let editPromptTemplate = '';

  onMount(async () => {
    try {
      const storedSettingsPromise = window.api.getStoreValue('enhancements') as Promise<EnhancementSettings | undefined>;
      const storedPromptsPromise = window.api.getStoreValue('enhancementPrompts') as Promise<EnhancementPrompt[] | undefined>;

      const [storedSettings, storedPrompts] = await Promise.all([storedSettingsPromise, storedPromptsPromise]);

      if (storedSettings) {
        settings.set({ ...storedSettings });
      }
      if (storedPrompts) {
        prompts.set([...storedPrompts]);
      }
    } catch (error) {
      window.api.log('error', 'Failed to load enhancement settings:', error);
    } finally {
      isLoading = false;
    }
  });

  $: if (!isLoading && $settings) {
      saveSettings($settings);
  }

  let saveTimeout: NodeJS.Timeout | null = null;
  const saveSettings = (currentSettings: EnhancementSettings) => {
      if (saveTimeout) clearTimeout(saveTimeout);
      saveTimeout = setTimeout(async () => {
          try {
              await window.api.setStoreValue('enhancements', currentSettings);
              window.api.log('info', 'Enhancement settings auto-saved.');
          } catch (error) {
              window.api.log('error', 'Failed to auto-save enhancement settings:', error);
          }
      }, 500);
  };

  const addPrompt = async () => {
    if (!newPromptName.trim() || !newPromptTemplate.trim()) {
      alert('Please provide both a name and a template for the new prompt.');
      return;
    }
    const newPrompt: EnhancementPrompt = {
      id: uuidv4(),
      name: newPromptName.trim(),
      template: newPromptTemplate.trim()
    };
    const currentPrompts = get(prompts);
    const updatedPrompts = [...currentPrompts, newPrompt];
    try {
      await window.api.setStoreValue('enhancementPrompts', updatedPrompts);
      prompts.set(updatedPrompts);
      newPromptName = '';
      newPromptTemplate = '';
      showAddPrompt = false;
      window.api.log('info', `Added new enhancement prompt: ${newPrompt.name}`);
    } catch (error) {
      window.api.log('error', 'Failed to save new prompt:', error);
      alert('Failed to save the new prompt.');
    }
  };

  const deletePrompt = async (idToDelete: string) => {
    if (idToDelete === 'default') return;
    if (!confirm('Are you sure you want to delete this prompt?')) return;

    const currentPrompts = get(prompts);
    const updatedPrompts = currentPrompts.filter(p => p.id !== idToDelete);
    try {
      await window.api.setStoreValue('enhancementPrompts', updatedPrompts);
      prompts.set(updatedPrompts);

      if (get(settings).activePromptId === idToDelete) {
        settings.update(s => ({ ...s, activePromptId: 'default' }));
        await saveSettings(get(settings));
      }
      window.api.log('info', `Deleted enhancement prompt ID: ${idToDelete}`);
    } catch (error) {
      window.api.log('error', 'Failed to delete prompt:', error);
      alert('Failed to delete the prompt.');
    }
  };

  const closeModal = () => {
    showPromptModal = false;
    currentPrompt = null;
    editPromptName = '';
    editPromptTemplate = '';
  };

  const viewPrompt = async (promptId: string) => {
    if (promptId === 'default') {
      try {
        const defaultTemplate = await window.api.getDefaultPromptContent();
        currentPrompt = {
          id: 'default',
          name: 'Default Prompt',
          template: defaultTemplate
        };
      } catch (err) {
        window.api.log('error', 'Failed to fetch default prompt content:', err);
        alert('Could not load default prompt content.');
        return;
      }
    } else {
      currentPrompt = get(prompts).find(p => p.id === promptId) || null;
    }

    if (currentPrompt) {
      modalMode = 'view';
      editPromptName = currentPrompt.name;
      editPromptTemplate = currentPrompt.template;
      showPromptModal = true;
    } else {
      window.api.log('error', `Prompt not found for viewing: ${promptId}`);
    }
  };

  const editPrompt = (promptToEdit: EnhancementPrompt) => {
    currentPrompt = promptToEdit;
    modalMode = 'edit';
    editPromptName = promptToEdit.name;
    editPromptTemplate = promptToEdit.template;
    showPromptModal = true;
  };

  const saveEditedPrompt = async () => {
    if (!currentPrompt || currentPrompt.id === 'default') return;
    if (!editPromptName.trim() || !editPromptTemplate.trim()) {
      alert('Prompt name and template cannot be empty.');
      return;
    }

    const updatedPrompt: EnhancementPrompt = {
      ...currentPrompt,
      name: editPromptName.trim(),
      template: editPromptTemplate.trim()
    };

    const currentPrompts = get(prompts);
    const updatedPrompts = currentPrompts.map(p => p.id === updatedPrompt.id ? updatedPrompt : p);

    try {
      await window.api.setStoreValue('enhancementPrompts', updatedPrompts);
      prompts.set(updatedPrompts);
      window.api.log('info', `Updated prompt: ${updatedPrompt.name}`);
      closeModal();
    } catch (error) {
      window.api.log('error', 'Failed to save updated prompt:', error);
      alert('Failed to save the updated prompt.');
    }
  };

</script>

<div class="p-4 space-y-6">
  <h2 class="text-xl font-semibold">Enhancement Settings</h2>

  {#if isLoading}
    <p>Loading settings...</p>
  {:else}
    <div class="bg-base-100 max-w-2xl space-y-6">

        <div class="form-control">
          <label class="label cursor-pointer">
            <span class="label-text font-semibold">Enable Enhancements</span>
            <input
              type="checkbox"
              class="toggle toggle-primary"
              bind:checked={$settings.enabled}
            />
          </label>
          <p class="text-sm opacity-70 ml-1">
            When enabled, transcriptions can be processed by an LLM to improve formatting, fix grammar, etc.
          </p>
            <label class="label"><span class="label-text-alt">Must be OpenAI API compatible.</span></label>
          </div>

        {#if $settings.enabled}
          <div class="divider pt-4">Enhancement Provider</div>

          <div class="flex flex-wrap gap-4 items-center">
             <div class="form-control">
               <label class="label cursor-pointer gap-2">
                 <input type="radio" name="enhancement-provider" class="radio radio-sm" value="openai" bind:group={$settings.provider} />
                 <span class="label-text">OpenAI</span>
               </label>
             </div>
             <div class="form-control">
               <label class="label cursor-pointer gap-2">
                 <input type="radio" name="enhancement-provider" class="radio radio-sm" value="gemini" bind:group={$settings.provider} />
                 <span class="label-text">Gemini</span>
               </label>
             </div>
             <div class="form-control">
               <label class="label cursor-pointer gap-2">
                 <input type="radio" name="enhancement-provider" class="radio radio-sm" value="custom" bind:group={$settings.provider} />
                 <span class="label-text">Custom</span>
               </label>
             </div>
          </div>

          {#if $settings.provider === 'openai'}
            <div class="mt-4 p-4 border border-base-300 rounded-md space-y-4">
               <h3 class="font-medium">OpenAI Configuration</h3>
               <div class="form-control">
                 <label class="label" for="openai-enh-api-key">
                   <span class="label-text">OpenAI API Key*</span>
                 </label>
                 <input id="openai-enh-api-key" type="password" placeholder="sk-..." class="input input-bordered input-sm w-full" bind:value={$settings.openaiApiKey} />
               </div>
               <div class="form-control">
                 <label class="label" for="openai-enh-model-select">
                   <span class="label-text">OpenAI Model*</span>
                 </label>
                 <select id="openai-enh-model-select" class="select select-bordered select-sm w-full max-w-xs" bind:value={$settings.openaiModel}>
                   <option value="gpt-4.1-mini">GPT-4.1 Mini</option>
                   <option value="gpt-4.1">GPT-4.1</option>
                 </select>
               </div>

            </div>
          {:else if $settings.provider === 'gemini'}
             <div class="mt-4 p-4 border border-base-300 rounded-md space-y-4">
                <h3 class="font-medium">Gemini Configuration</h3>
                <div class="form-control">
                  <label class="label" for="gemini-api-key">
                    <span class="label-text">Gemini API Key*</span>
                  </label>
                  <input id="gemini-api-key" type="password" placeholder="AIza..." class="input input-bordered input-sm w-full" bind:value={$settings.geminiApiKey} />
                </div>
                <div class="form-control">
                  <label class="label" for="gemini-model-select">
                    <span class="label-text">Gemini Model*</span>
                  </label>
                  <select id="gemini-model-select" class="select select-bordered select-sm w-full max-w-xs" bind:value={$settings.geminiModel}>
                    <option value="gemini-2.0-flash">Gemini 2.0 Flash</option>
                    <option value="gemini-2.0-flash-lite">Gemini 2.0 Flash Lite</option>
                    <option value="gemini-2.5-flash">Gemini 2.5 Flash</option>
                  </select>
                </div>
             </div>
          {:else if $settings.provider === 'custom'}
             <div class="mt-4 p-4 border border-base-300 rounded-md space-y-4">
                <h3 class="font-medium">Custom Provider Configuration</h3>

                <div class="form-control">
                  <label class="label" for="custom-base-url">
                    <span class="label-text">Base URL</span>
                  </label>
                  <input id="custom-base-url" type="text" placeholder="eg. https://api.mistral.ai/v1/" class="input input-bordered input-sm w-full" bind:value={$settings.customBaseUrl} />
                   <label class="label"><span class="label-text-alt text-xs">Must be OpenAI API compatible.</span></label>
                </div>

                <div class="form-control">
                  <label class="label" for="custom-model-name">
                    <span class="label-text">Model Name</span>
                  </label>
                  <input id="custom-model-name" type="text" placeholder="e.g. mistral-small-latest" class="input input-bordered input-sm w-full" bind:value={$settings.customModelName} />
                </div>


                 <div class="form-control">
                   <label class="label" for="custom-api-key">
                     <span class="label-text">API Key</span>
                   </label>
                   <input id="custom-api-key" type="password" placeholder="Enter API Key" class="input input-bordered input-sm w-full" bind:value={$settings.customApiKey} />
                 </div>

             </div>
          {/if}

          <div class="divider py-4">Context Variables</div>
          <p class="text-sm opacity-70 -mt-4 mb-4">
            Enable context sources to include them in your prompts using placeholders like <code class="kbd kbd-xs">{'{{context_screen}}'}</code>. (Note: Context capture is not yet implemented).
          </p>
          <div class="grid grid-cols-1 sm:grid-cols-2 gap-x-6 gap-y-2">
              <div class="form-control">
                  <label class="label cursor-pointer justify-start gap-3">
                      <input type="checkbox" class="toggle toggle-sm" bind:checked={$settings.useContextScreen} />
                      <span class="label-text">Screen Content</span>
                      <span class="tooltip tooltip-right" data-tip="Include text content from the active screen (if available). Use {'{{context_screen}}'} in prompt.">
                          <i class="ri-information-line opacity-50"></i>
                      </span>
                  </label>
              </div>
              <div class="form-control">
                  <label class="label cursor-pointer justify-start gap-3">
                      <input type="checkbox" class="toggle toggle-sm" bind:checked={$settings.useContextInputField} />
                      <span class="label-text">Input Field</span>
                       <span class="tooltip tooltip-right" data-tip="Include text content from the active input field (if available). Use {'{{context_input_field}}'} in prompt.">
                          <i class="ri-information-line opacity-50"></i>
                      </span>
                  </label>
              </div>
              <div class="form-control">
                  <label class="label cursor-pointer justify-start gap-3">
                      <input type="checkbox" class="toggle toggle-sm" bind:checked={$settings.useContextClipboard} />
                      <span class="label-text">Clipboard</span>
                       <span class="tooltip tooltip-right" data-tip="Include text content from the clipboard. Use {'{{context_clipboard}}'} in prompt.">
                          <i class="ri-information-line opacity-50"></i>
                      </span>
                  </label>
              </div>
          </div>

          <div class="divider pt-4">Active Enhancement Prompt</div>
          <div class="space-y-2">
             <div class="form-control">
                <label class="label cursor-pointer justify-start gap-2 p-2 rounded hover:bg-base-300 group">
                  <input type="radio" name="active-prompt" class="radio radio-sm" value="default" bind:group={$settings.activePromptId} />
                  <span class="label-text font-medium">Default Prompt</span>
                  <span class="text-xs opacity-60 ml-auto mr-2">(Basic formatting)</span>
                   <button
                     class="btn btn-xs btn-ghost opacity-0 group-hover:opacity-100 transition-opacity"
                     title="View Default Prompt"
                     on:click|stopPropagation|preventDefault={() => viewPrompt('default')}
                   >
                     <i class="ri-eye-line"></i>
                   </button>
                </label>
             </div>
             {#each $prompts as prompt (prompt.id)}
                <div class="form-control">
                  <label class="label cursor-pointer justify-start gap-2 p-2 rounded hover:bg-base-300 group">
                    <input type="radio" name="active-prompt" class="radio radio-sm" value={prompt.id} bind:group={$settings.activePromptId}  />
                    <span class="label-text flex-1 truncate" title={prompt.name}>{prompt.name}</span>
                    <button
                      class="btn btn-xs btn-ghost opacity-0 group-hover:opacity-100 transition-opacity mr-1"
                      title="Edit Prompt"
                      on:click|stopPropagation|preventDefault={() => editPrompt(prompt)}
                    >
                       <i class="ri-pencil-line"></i>
                    </button>

                    <button
                      class="btn btn-xs btn-ghost text-error opacity-0 group-hover:opacity-100 transition-opacity"
                      title="Delete Prompt"
                      on:click|stopPropagation|preventDefault={() => deletePrompt(prompt.id)}
                    >
                      <i class="ri-delete-bin-line"></i>
                    </button>
                  </label>
                </div>
             {/each}
          </div>

          <div class="mt-4">
             {#if showAddPrompt}
                <div class="p-4 border border-base-300 rounded-md space-y-3">
                   <h4 class="font-medium">Add New Prompt</h4>
                   <div class="form-control">
                      <label class="label py-1" for="new-prompt-name"><span class="label-text">Prompt Name:</span></label>
                      <input id="new-prompt-name" type="text" placeholder="e.g., Formal Report Style" class="input input-bordered input-sm w-full" bind:value={newPromptName} />
                   </div>
                    <div class="form-control">
                      <label class="label py-1" for="new-prompt-template"><span class="label-text">Prompt Template:</span></label>
                      <textarea id="new-prompt-template" class="textarea textarea-bordered w-full" rows="4" placeholder="Enter your prompt. Use {'{{transcription}}'} where the text should be inserted." bind:value={newPromptTemplate}></textarea>
                      <span class="pt-2 block-inline text-sm">Use <a target="_blank" class="underline" href="https://mustache.github.io/mustache.5.html">mustache templating</a>. Variables: <code class="kbd kbd-xs h-auto">{'{{transcription}}, {{dictionary_words}}, {{context_screen}}, {{context_clipboard}}, {{context_input_field}}'}</code></span>
                   </div>
                   <div class="flex justify-end gap-2 pt-2">
                      <button class="btn btn-sm btn-ghost" on:click={() => { showAddPrompt = false; newPromptName=''; newPromptTemplate=''; }}>Cancel</button>
                      <button class="btn btn-sm btn-primary" on:click={addPrompt}>Add Prompt</button>
                   </div>
                </div>
             {:else}
                <button class="btn btn-sm btn-outline" on:click={() => { showAddPrompt = true; }}>
                   <i class="ri-add-line"></i> Add Custom Prompt
                </button>
             {/if}
          </div>

        {/if}

      </div>
  {/if}
</div>

{#if showPromptModal && currentPrompt}
<dialog id="prompt_modal" class="modal modal-open">
  <div class="modal-box w-11/12 max-w-2xl">
    <h3 class="font-bold text-lg mb-4">
      {#if modalMode === 'view'}
        View Prompt: {currentPrompt.name}
      {:else if modalMode === 'edit'}
        Edit Prompt: {currentPrompt.name}
      {/if}
    </h3>

    {#if modalMode === 'view'}
      <div class="space-y-4">
        <div>
          <label class="label"><span class="label-text font-semibold">Name:</span></label>
          <p class="p-2 bg-base-200 rounded">{currentPrompt.name}</p>
        </div>
        <div>
          <label class="label"><span class="label-text font-semibold">Template:</span></label>
          <pre class="p-2 bg-base-200 rounded text-sm whitespace-pre-wrap break-words max-h-60 overflow-y-auto">{currentPrompt.template}</pre>
        </div>
      </div>
    {:else if modalMode === 'edit'}
      <div class="space-y-4">
         <div class="form-control">
            <label class="label py-1" for="edit-prompt-name"><span class="label-text">Prompt Name:</span></label>
            <input id="edit-prompt-name" type="text" class="input input-bordered w-full" bind:value={editPromptName} />
         </div>
          <div class="form-control">
            <label class="label py-1" for="edit-prompt-template"><span class="label-text">Prompt Template:</span></label>
            <textarea id="edit-prompt-template" class="textarea textarea-bordered w-full" rows="6" placeholder="Use {'{{transcription}}'} where the text should be inserted." bind:value={editPromptTemplate}></textarea>
         </div>
      </div>
    {/if}

    <div class="modal-action mt-6">
      <button class="btn btn-ghost" on:click={closeModal}>Close</button>
      {#if modalMode === 'edit'}
        <button class="btn btn-primary" on:click={saveEditedPrompt}>Save Changes</button>
      {/if}
    </div>
  </div>
  <form method="dialog" class="modal-backdrop">
    <button on:click={closeModal}>close</button>
  </form>
</dialog>
{/if}

================
File: src/renderer/src/components/settings/History.svelte
================
<script lang="ts">
  import { onMount, onDestroy } from "svelte";
  import { writable } from "svelte/store";

  const historyData = writable<PaginatedHistory | null>(null);
  const selectedEntry = writable<HistoryRecord | null>(null);
  const isLoading = writable(true);
  const error = writable<string | null>(null);

  const DEFAULT_PAGE_SIZE = 6;

  async function fetchHistory(
    page = 1,
    pageSize = DEFAULT_PAGE_SIZE,
  ): Promise<void> {
    isLoading.set(true);
    error.set(null);
    selectedEntry.set(null);
    try {
      const data = await window.api.getHistory(page, pageSize);
      if (data) {
        console.log(data);
        historyData.set(data);
      } else {
        historyData.set({
          entries: [],
          totalEntries: 0,
          totalPages: 0,
          currentPage: 1,
        });
        error.set("Failed to load history data.");
      }
      window.api.log("info", `History page ${page} loaded.`);
    } catch (err) {
      window.api.log("error", "Error fetching history:", err);
      error.set(`Error loading history: ${err.message}`);
      historyData.set({
        entries: [],
        totalEntries: 0,
        totalPages: 0,
        currentPage: 1,
      }); // Set empty state on error
    } finally {
      isLoading.set(false);
    }
  }

  async function deleteEntry(id: string): Promise<void> {
    if (!confirm("Are you sure you want to delete this history entry?")) return;
    try {
      const success = await window.api.deleteHistoryEntry(id);
      if (success) {
        window.api.log("info", `History entry ${id} deleted.`);
        // Refresh current page
        fetchHistory($historyData?.currentPage || 1);
      } else {
        error.set("Failed to delete entry.");
      }
    } catch (err) {
      window.api.log("error", `Error deleting history entry ${id}:`, err);
      error.set(`Error deleting entry: ${err.message}`);
    }
  }

  async function clearAll(): Promise<void> {
    if (
      !confirm(
        "Are you sure you want to delete ALL history entries? This cannot be undone.",
      )
    )
      return;
    try {
      const success = await window.api.clearAllHistory();
      if (success) {
        window.api.log("info", "All history cleared.");
        fetchHistory(1); // Refresh to show empty list
      } else {
        error.set("Failed to clear history.");
      }
    } catch (err) {
      window.api.log("error", "Error clearing history:", err);
      error.set(`Error clearing history: ${err.message}`);
    }
  }

  function selectEntry(entry: HistoryRecord): void {
    selectedEntry.set(entry);
  }

  function formatTimestamp(timestamp: number): string {
    return new Date(timestamp).toLocaleString();
  }

  function truncateText(text: string, maxLength = 100): string {
    if (!text) return "";
    return text.length > maxLength
      ? text.substring(0, maxLength) + "..."
      : text;
  }

  onMount(() => {
    fetchHistory();

    const cleanupResultListener = window.api.onTranscriptionResult(() => {
      window.api.log(
        "info",
        "History page received transcription result, refreshing list.",
      );
      fetchHistory(1); // Fetch the first page
    });

    onDestroy(() => {
      cleanupResultListener();
    });
  });
</script>

<div class="p-4 space-y-6">
  <div class="flex justify-between items-center">
    <h2 class="text-xl font-semibold">Latest Transcriptions</h2>
    {#if $historyData && $historyData.totalEntries > 0}
      <button
        class="btn btn-sm btn-outline btn-error"
        on:click={clearAll}
        disabled={$isLoading}
      >
        Clear All History
      </button>
    {/if}
  </div>

  {#if $isLoading}
    <div class="text-center p-10">
      <span class="loading loading-lg loading-spinner"></span>
      <p>Loading History...</p>
    </div>
  {:else if $error}
    <div class="alert alert-error">
      <svg
        xmlns="http://www.w3.org/2000/svg"
        class="stroke-current shrink-0 h-6 w-6"
        fill="none"
        viewBox="0 0 24 24"
        ><path
          stroke-linecap="round"
          stroke-linejoin="round"
          stroke-width="2"
          d="M10 14l2-2m0 0l2-2m-2 2l-2 2m2-2l2 2m7-2a9 9 0 11-18 0 9 9 0 0118 0z"
        /></svg
      >
      <span>{$error}</span>
    </div>
  {:else if $historyData && $historyData.entries.length > 0}
    <div class="grid grid-cols-1 md:grid-cols-3 gap-6">
      <!-- Entry List -->
      <div class="md:col-span-1 space-y-2 overflow-y-auto pr-2">
        {#each $historyData.entries as entry (entry.id)}
          <div
            class="p-3 rounded-md border cursor-pointer transition-colors"
            class:border-primary={$selectedEntry?.id === entry.id}
            class:bg-base-200={$selectedEntry?.id === entry.id}
            class:border-base-300={$selectedEntry?.id !== entry.id}
            class:hover:bg-base-200={$selectedEntry?.id !== entry.id}
            on:click={() => selectEntry(entry)}
            role="button"
            tabindex="0"
            on:keypress={(e) => {
              if (e.key === "Enter") selectEntry(entry);
            }}
          >
            <p class="text-sm font-medium truncate" title={entry.originalText}>
              {truncateText(entry.originalText)}
            </p>
            <p class="text-xs opacity-60 mt-1">
              {formatTimestamp(entry.timestamp)}
            </p>
          </div>
        {/each}

        <!-- Pagination -->
        {#if $historyData.totalPages > 1}
          <div class="join mt-4 flex justify-center">
            <button
              class="join-item btn btn-sm"
              disabled={$historyData.currentPage <= 1}
              on:click={() => fetchHistory($historyData.currentPage - 1)}
              >«</button
            >
            <button class="join-item btn btn-sm"
              >Page {$historyData.currentPage} / {$historyData.totalPages}</button
            >
            <button
              class="join-item btn btn-sm"
              disabled={$historyData.currentPage >= $historyData.totalPages}
              on:click={() => fetchHistory($historyData.currentPage + 1)}
              >»</button
            >
          </div>
        {/if}
      </div>

      <!-- Entry Details -->
      <div class="md:col-span-2">
        {#if $selectedEntry}
          <div class="card bg-base-100 border border-base-300">
            <div class="card-body">
              <div class="flex justify-between items-start mb-4">
                <h3 class="card-title text-lg">Details</h3>
                <button
                  class="btn btn-xs btn-ghost text-error"
                  title="Delete Entry"
                  on:click|stopPropagation={() =>
                    deleteEntry($selectedEntry!.id)}
                >
                  <i class="ri-delete-bin-line"></i> Delete
                </button>
              </div>

              <p class="text-xs opacity-60 mb-4">
                Recorded: {formatTimestamp($selectedEntry.timestamp)}
              </p>

              <div class="space-y-4">
                <div>
                  <h4 class="font-semibold mb-1">Original Transcription</h4>
                  <div
                    class="bg-base-200 p-3 rounded text-sm whitespace-pre-wrap break-words max-h-40 overflow-y-auto"
                  >
                    {$selectedEntry.originalText || "(empty)"}
                  </div>
                </div>

                {#if $selectedEntry.promptNameUsed}
                  <h4 class="font-semibold mb-1">Prompt: {$selectedEntry.promptNameUsed}</h4>
                {/if}
                {#if $selectedEntry.renderedPrompt}
                    <div class="collapse collapse-arrow bg-base-200/50">
                        <input type="checkbox" />
                        <div class="collapse-title text-xs font-medium">
                            View Rendered Prompt
                        </div>
                        <div class="collapse-content">
                            <pre class="text-xs whitespace-pre-wrap break-words overflow-y-auto">{$selectedEntry.renderedPrompt}</pre>
                        </div>
                    </div>
                {/if}

                {#if $selectedEntry.enhancedText}
                  <div>
                    <h4 class="font-semibold mb-1">Enhanced Text</h4>
                    <div
                      class="bg-success/10 p-3 rounded text-sm whitespace-pre-wrap break-words max-h-40 overflow-y-auto"
                    >
                      {$selectedEntry.enhancedText}
                    </div>

                  </div>
                {/if}
              </div>
            </div>
          </div>
        {:else}
          <div
            class="flex items-center justify-center h-full bg-base-200 rounded-md p-10"
          >
            <p class="opacity-60">
              Select an entry from the list to view details.
            </p>
          </div>
        {/if}
      </div>
    </div>
  {:else}
    <div class="text-center p-10 bg-base-200 rounded-md">
      <p class="opacity-60">No transcription history found.</p>
      <p class="text-sm mt-1 opacity-50">
        Recordings will appear here after they are transcribed.
      </p>
    </div>
  {/if}
</div>

================
File: src/renderer/src/components/settings/Permissions.svelte
================
<script lang="ts">
  import { onMount } from 'svelte';

  // Include 'not-determined' and 'unknown' as possible statuses from the API
  type PermissionStatus = 'checking' | 'granted' | 'not-granted' | 'unavailable' | 'denied' | 'restricted' | 'unknown' | 'not-determined';

  // Reactive state for permissions
  let accessibilityStatus: PermissionStatus = 'checking';
  let microphoneStatus: PermissionStatus = 'checking';
  let screenRecordingStatus: PermissionStatus = 'checking';
  let showManualInstructions = false; // State to show instructions after prompt

  // --- Accessibility ---
  async function checkAccessibilityStatus(): Promise<void> {
    window.api.log('debug', 'Checking Accessibility status...');
    accessibilityStatus = 'checking';
    showManualInstructions = false;
    try {
        const status = await window.api.getAccessibilityStatus();
        accessibilityStatus = status;
        window.api.log('info', 'Accessibility status:', status);
    } catch (error) {
        window.api.log('error', 'Error checking accessibility status:', error);
        accessibilityStatus = 'unavailable';
    }
  }

  async function requestAccessibility(): Promise<void> {
    window.api.log('info', 'Requesting Accessibility access (will prompt user)...');
    showManualInstructions = false;
    try {
        await window.api.requestAccessibilityAccess();
        window.api.log('info', 'Accessibility prompt shown. User needs to grant access in System Settings.');
        showManualInstructions = true;
        setTimeout(checkAccessibilityStatus, 5000);
    } catch (error) {
        window.api.log('error', 'Error requesting accessibility access:', error);
    }
  }

  // --- Media Permissions ---
  async function checkMediaStatus(mediaType: 'microphone' | 'screen'): Promise<void> {
      window.api.log('debug', `Checking ${mediaType} status...`);
      if (mediaType === 'microphone') microphoneStatus = 'checking';
      if (mediaType === 'screen') screenRecordingStatus = 'checking';

      try {
          // Ensure the status received from API matches our defined type
          const status = await window.api.getMediaPermissionStatus(mediaType) as PermissionStatus;
          if (mediaType === 'microphone') microphoneStatus = status;
          if (mediaType === 'screen') screenRecordingStatus = status;
          window.api.log('info', `${mediaType} status:`, status);
      } catch (error) {
          window.api.log('error', `Error checking ${mediaType} status:`, error);
          if (mediaType === 'microphone') microphoneStatus = 'unavailable';
          if (mediaType === 'screen') screenRecordingStatus = 'unavailable';
      }
  }

  async function requestMicrophone(): Promise<void> {
      window.api.log('info', 'Requesting Microphone access...');
      try {
          const granted = await window.api.requestMediaPermission('microphone');
          window.api.log('info', `Microphone access request result: ${granted}`);
          setTimeout(() => checkMediaStatus('microphone'), 1000);
          if (!granted) {
              window.api.log('warn', 'Microphone access denied or failed. Guide user to System Settings.');
          }
      } catch (error) {
          window.api.log('error', 'Error requesting microphone access:', error);
      }
  }

  function openScreenRecordingSettings(): void {
      window.api.log('info', 'Opening Screen Recording privacy settings via IPC...');
      // Use IPC to ask main process to open the URL
      window.api.openSettingsURL('x-apple.systempreferences:com.apple.preference.security?Privacy_ScreenCapture');
      setTimeout(() => checkMediaStatus('screen'), 5000);
  }

  // --- Lifecycle ---
  onMount(() => {
    if (navigator.platform.toUpperCase().indexOf('MAC') >= 0) {
        checkAccessibilityStatus();
        checkMediaStatus('microphone');
        checkMediaStatus('screen');
    } else {
        accessibilityStatus = 'unavailable';
        microphoneStatus = 'unavailable';
        screenRecordingStatus = 'unavailable';
    }
  });

  // Helper to get badge class
  function getBadgeClass(status: PermissionStatus): string {
      switch (status) {
          case 'granted': return 'badge-success';
          case 'denied':
          case 'restricted':
          case 'not-granted': return 'badge-error';
          case 'checking': return 'badge-ghost';
          default: return 'badge-ghost';
      }
  }

  // Helper to get status text
   function getStatusText(status: PermissionStatus): string {
      switch (status) {
          case 'granted': return 'Granted';
          case 'denied': return 'Denied';
          case 'restricted': return 'Restricted';
          case 'not-granted': return 'Not Granted';
          case 'checking': return 'Checking...';
          case 'not-determined': return 'Not Set';
          case 'unknown': return 'Unknown';
          default: return 'N/A';
      }
  }

</script>

<div class="p-4">
  <h2 class="text-2xl font-bold mb-6">Permissions</h2>

  <div class="bg-base-100 max-w-xl">
      <p class="text-sm opacity-70 mb-4">
        Vox Transcriber needs the following permissions to function properly.
      </p>

      <div class="space-y-6">
        <div class="flex items-start gap-4">
          <div class="bg-base-200 p-3 rounded-full mt-1">
            <span class="text-xl font-bold">⌨️</span>
          </div>
          <div class="flex-1">
            <h4 class="font-semibold">Accessibility Features</h4>
            <p class="text-sm opacity-70">Required for global keyboard shortcuts.</p>
            <div class="flex items-center gap-2 mt-1">
              <span class="badge {getBadgeClass(accessibilityStatus)} gap-1">
                 {#if accessibilityStatus !== 'checking' && accessibilityStatus !== 'unavailable'}
                    <span class="bg-white rounded-full w-2 h-2"></span>
                 {/if}
                 {getStatusText(accessibilityStatus)}
              </span>
            </div>
             {#if accessibilityStatus === 'not-granted'}
                <div class="mt-2">
                    <button class="btn btn-primary btn-sm" on:click={requestAccessibility}>
                      Request Access
                    </button>
                    {#if showManualInstructions}
                        <p class="text-xs text-warning mt-2">
                            System Settings should open. Please find 'Vox Transcriber' (or 'key-monitor') in the Accessibility list, click '+', add it if missing, and ensure the toggle is ON. You may need to restart the app.
                        </p>
                    {/if}
                </div>
             {/if}
          </div>
           {#if accessibilityStatus === 'granted'}
             <span class="text-sm text-success mt-1">✓</span>
           {:else if accessibilityStatus === 'checking'}
             <span class="loading loading-spinner loading-xs mt-1"></span>
           {/if}
        </div>

        <!-- Microphone Permission -->
        <div class="flex items-start gap-4">
          <div class="bg-base-200 p-3 rounded-full mt-1">
            <span class="text-xl">🎤</span>
          </div>
          <div class="flex-1">
            <h4 class="font-semibold">Microphone Access</h4>
            <p class="text-sm opacity-70">Required to capture audio for transcription.</p>
             <div class="flex items-center gap-2 mt-1">
              <span class="badge {getBadgeClass(microphoneStatus)} gap-1">
                 {#if microphoneStatus !== 'checking' && microphoneStatus !== 'unavailable'}
                    <span class="bg-white rounded-full w-2 h-2"></span>
                 {/if}
                 {getStatusText(microphoneStatus)}
              </span>
               {#if microphoneStatus === 'denied' || microphoneStatus === 'restricted'}
                  <p class="text-xs text-error">Please grant access in System Settings.</p>
               {/if}
            </div>
             {#if microphoneStatus === 'not-determined' || microphoneStatus === 'denied' || microphoneStatus === 'restricted'}
                <div class="mt-2">
                    <button class="btn btn-primary btn-sm" on:click={requestMicrophone}>
                      Request Access
                    </button>
                </div>
             {/if}
          </div>
           {#if microphoneStatus === 'granted'}
             <span class="text-sm text-success mt-1">✓</span>
           {:else if microphoneStatus === 'checking'}
             <span class="loading loading-spinner loading-xs mt-1"></span>
           {/if}
        </div>

        <!-- Screen Recording Permission -->
         <div class="flex items-start gap-4">
          <div class="bg-base-200 p-3 rounded-full mt-1">
            <span class="text-xl">🖥️</span>
          </div>
          <div class="flex-1">
            <h4 class="font-semibold">Screen Recording (macOS)</h4>
            <p class="text-sm opacity-70">Optional - For future contextual features.</p>
             <div class="flex items-center gap-2 mt-1">
              <span class="badge {getBadgeClass(screenRecordingStatus)} gap-1">
                 {#if screenRecordingStatus !== 'checking' && screenRecordingStatus !== 'unavailable'}
                    <span class="bg-white rounded-full w-2 h-2"></span>
                 {/if}
                 {getStatusText(screenRecordingStatus)}
              </span>
               {#if screenRecordingStatus === 'denied' || screenRecordingStatus === 'restricted' || screenRecordingStatus === 'not-granted'}
                  <p class="text-xs text-error">Please grant access in System Settings.</p>
               {/if}
               {#if screenRecordingStatus === 'unavailable'}
                 <p class="text-xs opacity-50">(macOS only feature)</p>
               {/if}
            </div>
             {#if screenRecordingStatus !== 'granted' && screenRecordingStatus !== 'checking' && screenRecordingStatus !== 'unavailable'}
                <div class="mt-2">
                    <button class="btn btn-primary btn-sm" on:click={openScreenRecordingSettings}>
                      Open Settings
                    </button>
                </div>
             {/if}
          </div>
           {#if screenRecordingStatus === 'granted'}
             <span class="text-sm text-success mt-1">✓</span>
           {:else if screenRecordingStatus === 'checking'}
             <span class="loading loading-spinner loading-xs mt-1"></span>
           {/if}
        </div>

      </div>

      <div class="bg-base-200 p-4 rounded-md mt-6">
        <h4 class="font-semibold mb-1">Why do we need these permissions?</h4>
        <p class="text-sm opacity-80">
          Accessibility features on macOS are required for global keyboard shortcuts. Microphone access is needed for audio capture. Screen recording is optional for potential future features.
        </p>
        <p class="text-sm opacity-80 mt-2">
          All processing is done locally on your device.
        </p>
      </div>
  </div>
</div>

================
File: src/renderer/src/components/settings/Shortcuts.svelte
================
<script lang="ts">
  import { onMount, onDestroy } from 'svelte';

  // Define the available modifier keys for the UI and their mapping to the names
  // the Swift tool and main process expect.
  const availableKeys = [
    { id: 'Fn', label: 'Fn', mapped: 'FN' }, // FN key is often problematic for global monitoring
    { id: 'ControlLeft', label: 'Control', mapped: 'CONTROL' }, // Use generic CONTROL
    { id: 'AltLeft', label: 'Option (Alt)', mapped: 'OPTION' },   // Use generic OPTION
    { id: 'MetaLeft', label: 'Command', mapped: 'COMMAND' },    // Use generic COMMAND
  ];

  // --- Component State ---
  let selectedKeyIds: string[] = []; // UI state (using 'id')
  // let saveSuccess = false; // Removed
  let lastAction = { action: '', key: '', time: 0 };
  let isRecording = false; // Local copy of recording state from main process
  let isToggleMode = false; // Local copy of toggle mode state

  // --- API Communication ---
  let cleanupShortcutListener: (() => void) | null = null;
  let cleanupStateListener: (() => void) | null = null;

  // Function to get the mapped key names (COMMAND, OPTION, etc.) from selected IDs
  function getMappedKeys(): string[] {
      return selectedKeyIds
          .map(id => availableKeys.find(k => k.id === id)?.mapped)
          .filter((mapped): mapped is string => !!mapped);
  }

  onMount(async () => {
    window.api.log('info', 'Shortcuts component mounted.');

    // Load stored *mapped* keys
    const storedMappedKeys = await window.api.getStoreValue('shortcutKeysMapped') as string[] | undefined;
    if (storedMappedKeys && Array.isArray(storedMappedKeys)) {
      selectedKeyIds = availableKeys
          .filter(k => storedMappedKeys.includes(k.mapped))
          .map(k => k.id);
      window.api.log('debug', 'Loaded mapped keys from store:', storedMappedKeys);
    } else {
        // Fallback (optional)
        const legacyStoredKeys = await window.api.getStoreValue('shortcutKeys') as string[] | undefined;
         if (legacyStoredKeys && Array.isArray(legacyStoredKeys)) {
             selectedKeyIds = legacyStoredKeys.filter(keyId => availableKeys.some(k => k.id === keyId));
             window.api.log('debug', 'Loaded legacy key IDs from store:', selectedKeyIds);
         }
    }

    // Tell main process to start monitoring the initially loaded keys
    await window.api.updateMonitoredKeys(getMappedKeys());
    window.api.log('info', 'Initial monitored keys sent to main process:', getMappedKeys());

    // Listen for raw shortcut actions (for debugging/UI feedback)
    cleanupShortcutListener = window.api.onShortcutAction((action, keyName) => {
      window.api.log('debug', `Raw Shortcut Action Received: ${action}, Key: ${keyName}`);
      lastAction = { action, key: keyName, time: Date.now() };
      // We don't directly act on these anymore, state comes from recordingStateUpdate
    });

    // Listen for recording state updates from the main process
    cleanupStateListener = window.api.onRecordingStateUpdate((state) => {
        window.api.log('info', 'Recording state update received:', state);
        isRecording = state.isRecording;
        isToggleMode = state.isToggleMode;
    });

    // TODO: Optionally request initial state from main process if needed immediately
    // const initialState = await window.api.getRecordingState(); // Need to add getRecordingState to preload/main
    // if(initialState) {
    //     isRecording = initialState.isRecording;
    //     isToggleMode = initialState.isToggleMode;
    // }
  });

  onDestroy(() => {
    window.api.log('info', 'Shortcuts component destroying, cleaning up listeners.');
    if (cleanupShortcutListener) cleanupShortcutListener();
    if (cleanupStateListener) cleanupStateListener();
    // Consider if main process should stop monitoring here or on app quit
  });

  // Debounce function for saving/updating keys
  let saveTimeout: NodeJS.Timeout | null = null;
  const updateKeys = (keys: string[]) => {
      if (saveTimeout) clearTimeout(saveTimeout);
      saveTimeout = setTimeout(async () => {
          const mappedKeysToSave = getMappedKeys(); // Recalculate mapped keys based on current selection
          window.api.log('info', 'Auto-saving shortcut keys:', mappedKeysToSave);
          try {
              await window.api.setStoreValue('shortcutKeysMapped', mappedKeysToSave);
              await window.api.updateMonitoredKeys(mappedKeysToSave);
              window.api.log('info', 'Shortcut keys auto-saved and monitoring updated.');
          } catch (error) {
               window.api.log('error', 'Failed to auto-save shortcut keys:', error);
          }
      }, 500); // Debounce 500ms
  };

  // Reactive statement to trigger update when selection changes
  $: if (selectedKeyIds) {
      // Need to ensure this runs *after* initial load from store in onMount
      // A simple check or a dedicated 'isLoaded' flag could work, but
      // debouncing might be sufficient if onMount finishes quickly.
      // Let's rely on debouncing for now.
      updateKeys(selectedKeyIds);
  }

</script>

<div class="p-4">
  <h2 class="text-2xl font-bold mb-6">Keyboard Shortcuts</h2>

  <div class="bg-base-100 max-w-xl">
      <p class="text-sm opacity-70 mb-4">
        Select modifier keys to control recording.
      </p>
      <ul class="text-sm opacity-70 mb-4 list-disc pl-5">
        <li><strong>Hold:</strong> Record while key is held down.</li>
        <li><strong>Double Click:</strong> Toggle recording on/off.</li>
        <li>Clicks get dismissed.</li>
      </ul>

      <div class="form-control space-y-2 flex flex-col">
        {#each availableKeys as key}
          <label class="label cursor-pointer justify-start gap-4">
            <input
              type="checkbox"
              bind:group={selectedKeyIds}
              value={key.id}
              class="checkbox checkbox-primary"
            />
            <span class="label-text">{key.label}</span>
          </label>
        {/each}
      </div>

      <!-- Removed Save Success Alert -->

      <!-- Optional: Display last raw action for debugging -->
       {#if lastAction.time > 0}
         <p class="text-xs opacity-50 mt-4">Last Raw Action: {lastAction.action} on {lastAction.key} at {new Date(lastAction.time).toLocaleTimeString()}</p>
       {/if}

    </div>
</div>

================
File: src/renderer/src/components/settings/Transcription.svelte
================
<script lang="ts">
  import { onMount } from 'svelte';
  import { writable, get } from 'svelte/store';
  import { AVAILABLE_LOCAL_MODELS } from '../../../../main/transcription/LocalWhisperService'

  const openaiApiKey = writable('');
  const openaiModel = writable<'gpt-4o-mini-transcribe' | 'gpt-4o-transcribe'>('gpt-4o-mini-transcribe');
  const provider = writable<'openai' | 'deepgram' | 'local'>('openai');
  const deepgramApiKey = writable('');
  const deepgramModel = writable<'nova-3' | 'enhanced' | 'whisper-large'>('nova-3');
  const localModelName = writable<string>('base.en');

  let isLoading = true;
  let downloadStatus = writable('');

  onMount(async () => {
    try {
      const initialSettings = await window.api.getStoreValue('transcription') as any || {}; 

      provider.set(initialSettings.provider || 'openai');
      openaiApiKey.set(initialSettings.openaiApiKey || '');
      openaiModel.set(initialSettings.openaiModel || 'gpt-4o-mini-transcribe');
      deepgramApiKey.set(initialSettings.deepgramApiKey || '');
      deepgramModel.set(initialSettings.deepgramModel || 'nova-3');
      localModelName.set(initialSettings.localModelName || 'base');

    } catch (error) {
      window.api.log('error', 'Failed to load transcription settings:', error);
    } finally {
      isLoading = false;
    }

  });

  let saveTimeout: NodeJS.Timeout | null = null;
  const saveSettings = () => {
      if (isLoading) return;
      if (saveTimeout) clearTimeout(saveTimeout);

      const currentSettings = {
          provider: get(provider),
          openaiApiKey: get(openaiApiKey),
          openaiModel: get(openaiModel),
          deepgramApiKey: get(deepgramApiKey),
          deepgramModel: get(deepgramModel),
          localModelName: get(localModelName)
      };

      saveTimeout = setTimeout(async () => {
          try {
              await window.api.setStoreValue('transcription', currentSettings);
              window.api.log('info', 'Transcription settings auto-saved.');
          } catch (error) {
              window.api.log('error', 'Failed to auto-save transcription settings:', error);
          }
      }, 500);
  };

  $: if (!isLoading) {
      const currentProviderValue = $provider;
      const currentApiKeyValue = $openaiApiKey;
      const currentModelValue = $openaiModel;
      const currentDeepgramApiKeyValue = $deepgramApiKey;
      const currentDeepgramModelValue = $deepgramModel;
      const currentLocalModelValue = $localModelName;

      saveSettings();
      if (currentProviderValue !== 'local' || (currentProviderValue === 'local' && currentLocalModelValue)) {
          downloadStatus.set('');
      }
  }

  const availableLocalModels = AVAILABLE_LOCAL_MODELS.map(model => ({ value: model, label: model }));

  async function downloadModel() {
      const modelToDownload = get(localModelName);
      if (!modelToDownload) {
          downloadStatus.set('Please select a model first.');
          return;
      }
      downloadStatus.set(`Downloading model ${modelToDownload}... (This may take a while)`);
      window.api.log('info', `Requesting download for model: ${modelToDownload}`);
      try {
          await window.api.invoke('download-local-model', modelToDownload);
          downloadStatus.set(`Model ${modelToDownload} downloaded successfully (or already exists).`);
          window.api.log('info', `Model download request successful for: ${modelToDownload}`);
      } catch (error: any) {
          window.api.log('error', `Failed to download model ${modelToDownload}:`, error);
          downloadStatus.set(`Error downloading model: ${error.message || 'Unknown error'}`);
      }
  }

</script>

<div class="p-4 space-y-6">
  <h2 class="text-xl font-semibold">Transcription Settings</h2>

  {#if isLoading}
    <p>Loading settings...</p>
  {:else}
    <div class="space-y-4">
       <!-- Provider Selection -->
       <div class="form-control">
         <label class="label" for="provider-select">
           <span class="label-text">Transcription Provider</span>
         </label>
         <select id="provider-select" class="select select-bordered w-full max-w-xs" bind:value={$provider}>
           <option value="openai">OpenAI Whisper API</option>
           <option value="deepgram">Deepgram API</option>
           <option value="local">Local Whisper Model</option> 
         </select>
       </div>

      {#if $provider === 'openai'}
        <div class="form-control">
          <label class="label" for="openai-api-key">
            <span class="label-text">OpenAI API Key (for Transcription)</span>
          </label>
          <input
            id="openai-api-key"
            type="password"
            placeholder="sk-..."
            class="input input-bordered w-full"
            bind:value={$openaiApiKey}
          />
          <label class="label">
             <span class="label-text-alt">Required for OpenAI transcription. Get key from <a href="https://platform.openai.com/api-keys" target="_blank" class="link link-primary">OpenAI Platform</a>.</span>
          </label>
        </div>

        <div class="form-control">
          <label class="label" for="openai-model-select">
            <span class="label-text">OpenAI Whisper Model</span>
          </label>
          <select id="openai-model-select" class="select select-bordered w-full max-w-xs" bind:value={$openaiModel}>
            <option value="gpt-4o-mini-transcribe">GPT-4o Mini Transcribe</option>
            <option value="gpt-4o-transcribe">GPT-4o Transcribe</option>
          </select>
           <label class="label">
             <span class="label-text-alt">Select the Whisper model to use.</span>
          </label>
        </div>
      {/if}

      {#if $provider === 'deepgram'}
        <div class="form-control">
          <label class="label" for="deepgram-api-key">
            <span class="label-text">Deepgram API Key</span>
          </label>
          <input
            id="deepgram-api-key"
            type="password"
            placeholder="..."
            class="input input-bordered w-full"
            bind:value={$deepgramApiKey}
          />
          <label class="label">
             <span class="label-text-alt">Required for Deepgram transcription. Get key from <a href="https://console.deepgram.com/signup" target="_blank" class="link link-primary">Deepgram Console</a>.</span>
          </label>
        </div>

        <div class="form-control">
          <label class="label" for="deepgram-model-select">
            <span class="label-text">Deepgram Model</span>
          </label>
          <select id="deepgram-model-select" class="select select-bordered w-full max-w-xs" bind:value={$deepgramModel}>
            <option value="nova-3">Nova 3 (Best)</option>
            <option value="enhanced">Enhanced</option>
            <option value="whisper-large">Whisper Large</option>
          </select>
           <label class="label">
             <span class="label-text-alt">Select the Deepgram model to use.</span>
          </label>
        </div>
      {/if}

      {#if $provider === 'local'}
         <div class="form-control w-full max-w-md space-y-4">
            <div>
                <label class="label" for="local-model-select">
                <span class="label-text">Local Whisper Model</span>
                <span class="label-text-alt">Models are downloaded on demand.</span>
                </label>
                <select
                id="local-model-select"
                class="select select-bordered w-full"
                bind:value={$localModelName}
                >
                {#each availableLocalModels as model}
                    <option value={model.value}>{model.label}</option>
                {/each}
                </select>
                <label class="label">
                    <span class="label-text-alt">Larger models are more accurate but slower and require more resources. `.en` models are English-only.</span>
                </label>
            </div>

            <div>
                <button class="btn btn-secondary btn-sm" on:click={downloadModel} disabled={!$localModelName}>
                    Download/Verify Model: {$localModelName || 'Select Model'}
                </button>
                {#if $downloadStatus}
                    <p class="text-sm mt-2">{$downloadStatus}</p>
                {/if}
                <p class="text-xs text-base-content/70 mt-1">
                    Clicking download will fetch the selected model if it's not already present locally.
                    This uses the `npx nodejs-whisper download` command.
                    Check console/logs for detailed progress.
                </p>
            </div>
         </div>
      {/if}

    </div>
  {/if}
</div>

================
File: src/renderer/src/components/WaterWaveAnimation.svelte
================
<script lang="ts">
  type Status = 'idle' | 'recording' | 'processing';

  export let status: Status = 'idle';
  export let size: string = '3rem';
  export let idleBorderColor: string = 'rgba(148, 163, 184, 0.3)';
  export let activeColor: string = '#33cfff';
  export let spinnerBorderWidth: string = '3px';
  export let waveDuration1: string = '4s';
  export let waveDuration2: string = '6s';
  export let waveDuration3: string = '10s';

  $: waveAnimationState = status === 'recording' ? 'running' : 'paused';

  $: containerStyle = `
    --size: ${size};
    --idle-border-color: ${idleBorderColor};
    --active-color: ${activeColor};
    --spinner-border-width: ${spinnerBorderWidth};
    --wave-anim-duration-1: ${waveDuration1};
    --wave-anim-duration-2: ${waveDuration2};
    --wave-anim-duration-3: ${waveDuration3};
  `;

</script>

<div
  class="status-indicator-container {status}"
  style={containerStyle}
  role="status"
  aria-live="polite"
  aria-label={status === 'processing' ? 'Processing' : (status === 'recording' ? 'Recording active' : 'Idle')}
>
  <div class="water-wave water-wave1" style="animation-play-state: {waveAnimationState};"></div>
  <div class="water-wave water-wave2" style="animation-play-state: {waveAnimationState};"></div>
  <div class="water-wave water-wave3" style="animation-play-state: {waveAnimationState};"></div>
</div>

<style>
  .status-indicator-container {
    position: relative;
    width: var(--size);
    height: var(--size);
    border-radius: 50%;
    box-sizing: border-box;
    overflow: hidden;
    border: var(--spinner-border-width) solid transparent;
    transition: border-color 0.3s ease-in-out;
  }

  .status-indicator-container.idle {
    border-color: var(--idle-border-color);
  }
  .status-indicator-container.idle .water-wave {
    opacity: 0.6;
    transform: scale(1);
  }

  .status-indicator-container.recording {
    border-color: var(--idle-border-color);
  }
  .status-indicator-container.recording .water-wave {
    opacity: 1;
    transform: scale(1);
  }

  .status-indicator-container.processing {
    border-color: color-mix(in srgb, var(--active-color) 15%, transparent);
    border-left-color: var(--active-color);
    animation: spin 1s linear infinite;
  }
  .status-indicator-container.processing .water-wave {
    opacity: 0;
    transform: scale(0.8);
  }

  .water-wave {
    position: absolute;
    width: 200%;
    height: 200%;
    border-radius: 40%;
    background-color: var(--active-color);
    animation-name: water-waves;
    animation-timing-function: linear;
    animation-iteration-count: infinite;
    opacity: 0;
    transform: scale(1);
    transition: opacity 0.4s ease-in-out, transform 0.4s ease-in-out;
    animation-play-state: paused;
  }

  .water-wave1 {
    top: 40%;
    left: -25%;
    opacity: 0.7;
    border-radius: 40%;
    animation-duration: var(--wave-anim-duration-1);
  }

  .water-wave2 {
    top: 45%;
    left: -35%;
    opacity: 0.5;
    border-radius: 35%;
    animation-duration: var(--wave-anim-duration-2);
  }

  .water-wave3 {
    top: 50%;
    left: -35%;
    opacity: 0.3;
    border-radius: 33%;
    animation-duration: var(--wave-anim-duration-3);
  }

  @keyframes water-waves {
    0% { transform: rotate(0deg); }
    100% { transform: rotate(360deg); }
  }

  @keyframes spin {
    0% { transform: rotate(0deg); }
    100% { transform: rotate(360deg); }
  }
</style>

================
File: src/renderer/src/lib/audioRecorder.ts
================
import { writable } from 'svelte/store';

export const recordingStatus = writable<'idle' | 'recording' | 'processing' | 'error'>('idle');
export const transcriptionResult = writable<string | null>(null);
export const transcriptionError = writable<string | null>(null);

let mediaRecorder: MediaRecorder | null = null;
let cancelRequested = false;
let audioChunks: Blob[] = [];
let audioStream: MediaStream | null = null;
let audioContext: AudioContext | null = null;

const SILENCE_THRESHOLD = 0.1;
const DESIRED_AUDIO_BITRATE = 32000;

export function initializeAudioRecorder(): () => void {
  window.api.log('info', 'Initializing audio recorder listeners...');

  const cleanupStart = window.api.onStartRecording(() => {
    cancelRequested = false;
    startRecording();
  });
  const cleanupStop = window.api.onStopRecording(() => {
    stopRecording();
  });
  const cleanupCancel = window.api.onCancelRecording(() => {
      window.api.log('info', 'Cancel recording requested (IPC). Setting flag and forcing cleanup.');
      cancelRequested = true;
      const recorderToStop = mediaRecorder;
      const streamToStop = audioStream;
      mediaRecorder = null;
      audioStream = null;
      audioChunks = [];
      streamToStop?.getTracks().forEach(track => {
          try { track.stop(); } catch (e) { window.api.log('warn', 'Error stopping audio track during cancel:', e); }
      });
      window.api.log('debug', 'Skipping mediaRecorder.stop() during forced cancel.');
  });
  const cleanupResult = window.api.onTranscriptionResult(handleTranscriptionResult);
  const cleanupError = window.api.onTranscriptionError(handleTranscriptionError);
  const cleanupStatus = window.api.onRecordingStatus(handleRecordingStatus);

  return () => {
    window.api.log('info', 'Cleaning up audio recorder listeners...');
    cleanupStart();
    cleanupStop();
    cleanupCancel();
    cleanupResult();
    cleanupError();
    cleanupStatus();
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      try { mediaRecorder.stop(); } catch(e) {}
    }
    if (audioStream) {
      audioStream.getTracks().forEach(track => { try {track.stop();} catch(e) {} });
    }
    if (audioContext && audioContext.state !== 'closed') {
        audioContext.close().catch(e => window.api.log('warn', 'Error closing AudioContext on cleanup:', e));
        audioContext = null;
    }
    cancelRequested = false;
  };
}

async function startRecording(): Promise<void> {
  window.api.log('info', 'Start recording requested...');
  cancelRequested = false;
  transcriptionResult.set(null);
  transcriptionError.set(null);

  if (mediaRecorder) {
    window.api.log('warn', `Start request ignored. Recorder instance already exists (state: ${mediaRecorder?.state}).`);
    return;
  }
  if (cancelRequested) {
     window.api.log('warn', 'Start request ignored. Cancel flag already set.');
     return;
  }

  let obtainedStream: MediaStream | null = null;

  try {
    obtainedStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    if (cancelRequested) {
        window.api.log('warn', 'Recording cancelled after getUserMedia was granted. Cleaning up stream.');
        obtainedStream?.getTracks().forEach(track => track.stop());
        return;
    }
    audioStream = obtainedStream;
    window.api.log('info', 'Microphone access granted.');

    const options = getSupportedMimeTypeAndOptions();
    window.api.log('info', `Using MediaRecorder options: ${JSON.stringify(options)}`);

    if (cancelRequested) {
        window.api.log('warn', 'Recording cancelled before creating MediaRecorder.');
        audioStream?.getTracks().forEach(track => track.stop());
        audioStream = null;
        return;
    }

    const localRecorder = new MediaRecorder(audioStream, options);
    mediaRecorder = localRecorder;
    audioChunks = [];

    localRecorder.ondataavailable = (event) => {
      if (cancelRequested) {
          return;
      }
      if (event.data.size > 0) {
        audioChunks.push(event.data);
      }
    };

    localRecorder.onstop = async () => {
      const currentRecorderRef = mediaRecorder;
      const currentMimeType = currentRecorderRef?.mimeType || options.mimeType || 'audio/webm';
      window.api.log('info', `MediaRecorder stopped. Cancelled flag: ${cancelRequested}`);

      if (cancelRequested) {
          window.api.log('info', 'Recording cancelled (detected in onstop), discarding audio data.');
          cleanupAfterRecording(true);
          return;
      }

      if (audioChunks.length === 0) {
          window.api.log('warn', 'No audio data recorded (or cleared due to cancel).');
          cleanupAfterRecording(false);
          return;
      }

      const audioBlob = new Blob(audioChunks, { type: currentMimeType });
      window.api.log('info', `Combined audio blob size: ${audioBlob.size} bytes, type: ${audioBlob.type}`);

      let processingError = null;
      try {
        const arrayBuffer = await audioBlob.arrayBuffer();

        if (cancelRequested) {
            window.api.log('warn', 'Recording cancelled before audio processing/sending.');
            throw new Error("Cancelled before processing");
        }

        if (!audioContext || audioContext.state === 'closed') {
            try {
                 audioContext = new AudioContext();
            } catch (acError) {
                window.api.log('warn', 'Could not create AudioContext, falling back to default.', acError);
                audioContext = new AudioContext();
            }
        }

        let audioBuffer: AudioBuffer;
        try {
            audioBuffer = await audioContext.decodeAudioData(arrayBuffer.slice(0));
        } catch (decodeError) {
             window.api.log('error', 'Audio decode failed:', decodeError);
             throw new Error(`Audio decode failed: ${decodeError.message}`);
        }

        window.api.log('info', `Audio decoded: Duration=${audioBuffer.duration.toFixed(2)}s, SampleRate=${audioBuffer.sampleRate}Hz`);

        if (isAudioSilent(audioBuffer)) {
            window.api.log('info', 'Detected silence, skipping transcription. Notifying main process.');
            window.api.notifySilenceCancellation();
            throw new Error("Silent audio detected");
        }

         if (cancelRequested) {
            window.api.log('warn', 'Recording cancelled just before sending to main process.');
            throw new Error("Cancelled before sending");
        }

        const audioPayload = { audioData: arrayBuffer, mimeType: currentMimeType };
        window.api.log('info', `Sending audio (${(arrayBuffer.byteLength / 1024).toFixed(1)} KB) for transcription...`);
        await window.api.transcribeAudio(audioPayload);
        window.api.log('info', 'Audio data sent to main process.');

      } catch (error) {
        if (error.message.startsWith("Cancelled") || error.message.startsWith("Silent")) {
            window.api.log('info', `Processing skipped due to: ${error.message}`);
        } else {
            window.api.log('error', 'Error during audio processing or sending:', error);
            processingError = error;
        }
      } finally {
          cleanupAfterRecording(cancelRequested || (processingError && processingError.message.startsWith("Cancelled")));
          if (processingError && !processingError.message.startsWith("Cancelled") && !processingError.message.startsWith("Silent")) {
              handleTranscriptionError(`Processing error: ${processingError.message || processingError}`);
          }
      }
    };

    localRecorder.onerror = (event) => {
       window.api.log('error', 'MediaRecorder error:', (event as ErrorEvent).error || event);
       handleTranscriptionError(`Recording error: ${(event as ErrorEvent).error?.message || 'Unknown recording error'}`);
       cleanupAfterRecording(cancelRequested);
    };

    if (cancelRequested) {
         window.api.log('warn', 'Recording cancelled just before MediaRecorder.start().');
         cleanupAfterRecording(true);
         return;
    }

    try {
        localRecorder.start();
        window.api.log('info', `MediaRecorder started (Bitrate: ${localRecorder.audioBitsPerSecond || 'default'}, MimeType: ${localRecorder.mimeType}).`);
        window.api.notifyRecorderStarted();
    } catch (startError) {
         window.api.log('error', 'Error calling MediaRecorder.start():', startError);
         handleTranscriptionError(`Failed to start recorder: ${startError.message}`);
         cleanupAfterRecording(false);
    }

  } catch (err) {
     window.api.log('error', 'Error accessing microphone or starting recorder:', err);
     let errorMessage = 'Unknown error';
     if (err instanceof Error) {
         errorMessage = err.message;
         if (err.name === 'NotAllowedError') {
             errorMessage = 'Microphone permission denied.';
         } else if (err.name === 'NotFoundError') {
             errorMessage = 'No microphone found.';
         } else if (err.name === 'NotReadableError') {
             errorMessage = 'Microphone is already in use or hardware error.';
         }
     }
     handleTranscriptionError(`Microphone access error: ${errorMessage}`);
     if (obtainedStream) {
        obtainedStream.getTracks().forEach(track => track.stop());
     }
     audioStream = null;
     mediaRecorder = null;
  }
}

function cleanupAfterRecording(isCancellationOrSilence: boolean): void {
    window.api.log('debug', `Cleaning up audio resources (Is Cancellation/Silence: ${isCancellationOrSilence})`);
    audioStream?.getTracks().forEach(track => {
        try { track.stop(); } catch(e) { window.api.log('warn', 'Error stopping track in cleanup:', e); }
    });
    audioStream = null;
    mediaRecorder = null;
    audioChunks = [];
    window.api.log('debug', `Cleanup done, cancelRequested flag state preserved: ${cancelRequested}`);
}

export function stopRecording(): void {
  window.api.log('info', `Stop recording requested. Current state: ${mediaRecorder?.state}. Cancelled: ${cancelRequested}`);
  if (cancelRequested) {
      window.api.log('warn', 'Stop ignored because cancelRequested is true.');
      cleanupAfterRecording(true);
      return;
  }
  const recorder = mediaRecorder;
  if (recorder && recorder.state === 'recording') {
    try {
        recorder.stop();
    } catch (e) {
        window.api.log('error', 'Error calling MediaRecorder.stop():', e);
        handleTranscriptionError(`Failed to stop recorder: ${e instanceof Error ? e.message : String(e)}`);
        cleanupAfterRecording(false);
    }
  } else if (recorder && recorder.state === 'inactive') {
      window.api.log('warn', 'Stop requested but recorder is already inactive. Cleaning up.');
      cleanupAfterRecording(false);
  } else {
     window.api.log('warn', `Stop requested but no active/inactive recorder found or state is ${recorder?.state}.`);
     cleanupAfterRecording(false);
  }
}

function handleTranscriptionResult(text: string): void {
  window.api.log('info', `Transcription result received: "${text}"`);
  transcriptionResult.set(text);
  transcriptionError.set(null);
}

function handleTranscriptionError(error: string): void {
  window.api.log('error', `Transcription/Processing error received: ${error}`);
  transcriptionError.set(error);
  transcriptionResult.set(null);
}

function handleRecordingStatus(status: 'idle' | 'recording' | 'processing' | 'error'): void {
   window.api.log('debug', `[Renderer/audioRecorder] handleRecordingStatus received status from main: ${status}`);
   recordingStatus.set(status);
}

function getSupportedMimeTypeAndOptions(): MediaRecorderOptions {
    const types = [
        'audio/webm;codecs=opus',
        'audio/ogg;codecs=opus',
        'audio/webm;codecs=vp8',
        'audio/webm',
        'audio/ogg',
    ];

    let supportedMimeType = '';
    for (const type of types) {
        if (MediaRecorder.isTypeSupported(type)) {
            supportedMimeType = type;
            break;
        }
    }

    if (!supportedMimeType) {
         window.api.log('warn', 'No preferred MIME type supported, using browser default.');
    }

    const options: MediaRecorderOptions = {};
    if (supportedMimeType) {
        options.mimeType = supportedMimeType;
    }
    options.audioBitsPerSecond = DESIRED_AUDIO_BITRATE;

    return options;
}

function isAudioSilent(audioBuffer: AudioBuffer): boolean {
    const channelCount = audioBuffer.numberOfChannels;
    const threshold = SILENCE_THRESHOLD;
    let maxAmplitude = 0;

    for (let i = 0; i < channelCount; i++) {
        const channelData = audioBuffer.getChannelData(i);
        for (let j = 0; j < channelData.length; j++) {
            const amplitude = Math.abs(channelData[j]);
            if (amplitude > maxAmplitude) {
                 maxAmplitude = amplitude;
                 if (maxAmplitude > threshold) {
                     window.api.log('debug', `Detected amplitude ${maxAmplitude.toFixed(4)} > threshold ${threshold}. Not silent.`);
                     return false;
                 }
            }
        }
    }
    window.api.log('debug', `Max detected amplitude: ${maxAmplitude.toFixed(4)} (Threshold: ${threshold}). Silent.`);
    return maxAmplitude <= threshold;
}

export function get<T>(store: { subscribe: (cb: (value: T) => void) => () => void }): T {
  let value: T;
  const unsubscribe = store.subscribe(v => value = v);
  unsubscribe();
  return value;
}

================
File: src/renderer/src/App.svelte
================
<script lang="ts">
  import { onMount, onDestroy } from 'svelte';
  import AppLayout from './components/layout/AppLayout.svelte';
  import Dashboard from './components/settings/Dashboard.svelte';
  import Dictionary from './components/settings/Dictionary.svelte';
  import History from './components/settings/History.svelte';
  import Enhancements from './components/settings/Enhancements.svelte';
  import Permissions from './components/settings/Permissions.svelte';
  import Shortcuts from './components/settings/Shortcuts.svelte';
  import Transcription from './components/settings/Transcription.svelte';
  import { initializeAudioRecorder } from './lib/audioRecorder';

  let activePage = 'dashboard';

  let cleanupAudioRecorder: (() => void) | null = null;

  onMount(() => {
    cleanupAudioRecorder = initializeAudioRecorder();
  });

  onDestroy(() => {
    if (cleanupAudioRecorder) {
      cleanupAudioRecorder();
    }
  });
</script>

<AppLayout bind:activePage>
  {#if activePage === 'dashboard'}
    <Dashboard />
  {:else if activePage === 'shortcuts'}
    <Shortcuts />
  {:else if activePage === 'transcription'}
    <Transcription />
  {:else if activePage === 'enhancements'}
    <Enhancements />
  {:else if activePage === 'dictionary'}
    <Dictionary />
  {:else if activePage === 'permissions'}
    <Permissions />
  {:else if activePage === 'history'}
    <History />
  {/if}
</AppLayout>

================
File: src/renderer/src/env.d.ts
================
/// <reference types="svelte" />
/// <reference types="vite/client" />

================
File: src/renderer/src/main.ts
================
import { mount } from 'svelte'

import './assets/main.css'

import App from './App.svelte'

const app = mount(App, {
  target: document.getElementById('app')!
})

export default app

================
File: src/renderer/src/widget.ts
================
import WidgetApp from './WidgetApp.svelte';
import { mount } from 'svelte';

import './assets/widget.css'

const app = mount(WidgetApp, { target: document.getElementById("widget-root") });

================
File: src/renderer/src/WidgetApp.svelte
================
<script lang="ts">
  import { onMount, onDestroy } from 'svelte';
  import { writable } from 'svelte/store';
  import { fade } from 'svelte/transition';
  import WaterWaveAnimation from './components/WaterWaveAnimation.svelte';

  type OverallStatus = 'idle' | 'recording' | 'processing' | 'error';
  type WidgetDisplayState = 'idle' | 'initializing' | 'recording' | 'processing' | 'error';

  const widgetDisplayState = writable<WidgetDisplayState>('idle');
  let currentDisplayState: WidgetDisplayState = 'idle';

  let recorderActuallyStarted = false;
  let currentOverallStatus: OverallStatus = 'idle';

  let visible = false;
  let elapsedTime = 0;
  let timer: NodeJS.Timeout | undefined = undefined;

  let cleanupStatusListener: (() => void) | null = null;
  let cleanupRecorderStartedListener: (() => void) | null = null;

  function startTimer() {
    stopTimer();
    timer = setInterval(() => {
      elapsedTime += 1;
    }, 1000);
  }

  function stopTimer() {
    if (timer) {
      clearInterval(timer);
      timer = undefined;
      elapsedTime = 0;
    }
  }

  function formatTime(seconds: number): string {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins}:${secs < 10 ? '0' : ''}${secs}`;
  }

  onMount(() => {
    const unsubscribeDisplayState = widgetDisplayState.subscribe((newState) => {
      currentDisplayState = newState;
      visible = ['recording', 'processing'].includes(newState);
    });

    cleanupStatusListener = window.widgetApi.onStatusUpdate((newStatus: OverallStatus) => {
      currentOverallStatus = newStatus;

      switch (newStatus) {
        case 'recording':
          if (!recorderActuallyStarted) {
            widgetDisplayState.set('initializing');
            if (timer) stopTimer();
          } else {
            widgetDisplayState.set('recording');
            if (!timer) startTimer();
          }
          break;
        case 'processing':
          stopTimer();
          recorderActuallyStarted = false;
          widgetDisplayState.set('processing');
          break;
        case 'idle':
        case 'error':
          stopTimer();
          recorderActuallyStarted = false;
          widgetDisplayState.set(newStatus === 'error' ? 'error' : 'idle');
          break;
      }
    });

    cleanupRecorderStartedListener = window.widgetApi.onRecorderStarted(() => {
      recorderActuallyStarted = true;
      if (currentOverallStatus === 'recording') {
        widgetDisplayState.set('recording');
        startTimer();
      }
    });

    return () => {
      stopTimer();
      unsubscribeDisplayState();
      cleanupStatusListener?.();
      cleanupRecorderStartedListener?.();
    };
  });

  onDestroy(() => {
    stopTimer();
  });
</script>

{#if visible}
<div
  class="fixed bottom-6 left-1/2 transform -translate-x-1/2 z-50"
  transition:fade={{ duration: 150 }}
>
  <div class="flex items-center bg-black/85 backdrop-blur-md rounded-full py-1.5 px-4 shadow-lg border border-gray-600/30 gap-2">
    <div>
      <WaterWaveAnimation
        status={currentDisplayState === 'error' ? 'idle' : currentDisplayState}
        size="1.5rem"
        borderColor="rgba(148, 163, 184, 0.3)"
      />
    </div>

    <div class="text-xs text-gray-200 font-medium w-20 text-center flex items-center justify-center h-[1.5rem]">
      {#if currentDisplayState === 'recording'}
        <span class="tabular-nums">{formatTime(elapsedTime)}</span>
      {:else if currentDisplayState === 'processing'}
        <div class="flex space-x-1 justify-center items-center">
          <span class="sr-only">Loading...</span>
          <div class='h-1 w-1 bg-gray-300 rounded-full animate-bounce [animation-delay:-0.3s]'></div>
          <div class='h-1 w-1 bg-gray-300 rounded-full animate-bounce [animation-delay:-0.15s]'></div>
          <div class='h-1 w-1 bg-gray-300 rounded-full animate-bounce'></div>
        </div>
      {:else if currentDisplayState === 'error'}
        Error
      {/if}
    </div>
  </div>
</div>
{/if}

================
File: src/renderer/index.html
================
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Electron</title>
    <!-- https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP -->
    <meta
      http-equiv="Content-Security-Policy"
      content="default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data:"
    />
  </head>

  <body>
    <div id="app"></div>
    <script type="module" src="/src/main.ts"></script>
  </body>
</html>

================
File: src/renderer/widget.html
================
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <title>Vox Recorder Widget</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <style>
      html, body {
        margin: 0;
        padding: 0;
        width: 100vw;
        height: 100vh;
        overflow: hidden;
      }
      #widget-root {
        width: 100vw;
        height: 100vh;
        display: flex;
        align-items: center;
        justify-content: center;
      }
    </style>
  </head>
  <body>
    <div id="widget-root"></div>
    <script type="module" src="./src/widget.ts"></script>
  </body>
</html>

================
File: .editorconfig
================
root = true

[*]
charset = utf-8
indent_style = space
indent_size = 2
end_of_line = lf
insert_final_newline = true
trim_trailing_whitespace = true

================
File: .gitignore
================
node_modules
dist
out
.DS_Store
.eslintcache
*.log*

================
File: .prettierignore
================
out
dist
pnpm-lock.yaml
LICENSE.md
tsconfig.json
tsconfig.*.json

================
File: .prettierrc.yaml
================
# singleQuote: true
# semi: false
# printWidth: 100
# trailingComma: none
# plugins:
#   - prettier-plugin-svelte
# overrides:
#   - files: '*.svelte'
#     options:
#       parser: svelte

================
File: dev-app-update.yml
================
provider: generic
url: https://example.com/auto-updates
updaterCacheDirName: vox-test-updater

================
File: electron-builder.yml
================
appId: com.electron.app
productName: vox-test
directories:
  buildResources: build
files:
  - '!**/.vscode/*'
  - '!src/*'
  - '!electron.vite.config.{js,ts,mjs,cjs}'
  - '!{.eslintignore,.eslintrc.cjs,.prettierignore,.prettierrc.yaml,dev-app-update.yml,CHANGELOG.md,README.md}'
  - '!{.env,.env.*,.npmrc,pnpm-lock.yaml}'
  - '!{tsconfig.json,tsconfig.node.json,tsconfig.web.json}'
asarUnpack:
  - resources/**
win:
  executableName: vox-test
nsis:
  artifactName: ${name}-${version}-setup.${ext}
  shortcutName: ${productName}
  uninstallDisplayName: ${productName}
  createDesktopShortcut: always
mac:
  entitlementsInherit: build/entitlements.mac.plist
  extendInfo:
    - NSMicrophoneUsageDescription: This app requires microphone access to capture audio for transcription.
    - NSScreenCaptureUsageDescription: This app requires screen capture access for potential future contextual transcription features. # For Screen Recording
    - NSAccessibilityUsageDescription: This app requires Accessibility access to enable global keyboard shortcuts. # For Accessibility
    # - NSDocumentsFolderUsageDescription: Application requests access to the user's Documents folder. # Keep if needed
    # - NSDownloadsFolderUsageDescription: Application requests access to the user's Downloads folder. # Keep if needed
  notarize: false
dmg:
  artifactName: ${name}-${version}.${ext}
linux:
  target:
    - AppImage
    - snap
    - deb
  maintainer: electronjs.org
  category: Utility
appImage:
  artifactName: ${name}-${version}.${ext}
npmRebuild: false
publish:
  provider: generic
  url: https://example.com/auto-updates

================
File: electron.vite.config.ts
================
import { defineConfig, externalizeDepsPlugin } from 'electron-vite'
import { svelte } from '@sveltejs/vite-plugin-svelte'
import tailwindcss from '@tailwindcss/vite'

export default defineConfig({
  main: {
    plugins: [externalizeDepsPlugin({ exclude: ['electron-store'] })]
  },
  preload: {
    build: {
      rollupOptions: {
        input: {
          index: 'src/preload/index.ts', // Default preload
          widget: 'src/preload/widget.ts' // Widget preload
        }
      }
    },
    plugins: [externalizeDepsPlugin()]
  },
  renderer: {
    // Specify multiple HTML entry points
    build: {
      rollupOptions: {
        input: {
          index: 'src/renderer/index.html', // Default entry
          widget: 'src/renderer/widget.html' // Widget entry
        }
      }
    },
    plugins: [svelte(), tailwindcss()]
  }
})

================
File: eslint.config.mjs
================
import tseslint from '@electron-toolkit/eslint-config-ts'
import eslintConfigPrettier from '@electron-toolkit/eslint-config-prettier'
import eslintPluginSvelte from 'eslint-plugin-svelte'

// export default tseslint.config(
//   { ignores: ['**/node_modules', '**/dist', '**/out'] },
//   tseslint.configs.recommended,
//   eslintPluginSvelte.configs['flat/recommended'],
//   {
//     files: ['**/*.svelte'],
//     languageOptions: {
//       parserOptions: {
//         parser: tseslint.parser
//       }
//     }
//   },
//   {
//     files: ['**/*.{tsx,svelte}'],
//     rules: {
//       'svelte/no-unused-svelte-ignore': 'off'
//     }
//   },
//   eslintConfigPrettier
// )

================
File: package.json
================
{
  "name": "vox-test",
  "version": "1.0.0",
  "description": "An Electron application with Svelte and TypeScript",
  "main": "./out/main/index.js",
  "author": "example.com",
  "homepage": "https://electron-vite.org",
  "scripts": {
    "format": "prettier --plugin prettier-plugin-svelte --write .",
    "lint": "eslint --cache .",
    "typecheck:node": "tsc --noEmit -p tsconfig.node.json --composite false",
    "svelte-check": "svelte-check --tsconfig ./tsconfig.json",
    "typecheck": "npm run typecheck:node && npm run svelte-check",
    "start": "electron-vite preview",
    "dev": "electron-vite dev",
    "build": "npm run typecheck && electron-vite build",
    "postinstall": "electron-builder install-app-deps",
    "build:unpack": "npm run build && electron-builder --dir",
    "build:win": "npm run build && electron-builder --win",
    "build:mac": "npm run build && electron-builder --mac",
    "build:linux": "npm run build && electron-builder --linux"
  },
  "dependencies": {
    "@deepgram/sdk": "^3.11.3",
    "@electron-toolkit/preload": "^3.0.1",
    "@electron-toolkit/utils": "^4.0.0",
    "@tailwindcss/vite": "^4.1.3",
    "@types/uuid": "^10.0.0",
    "better-sqlite3": "^11.9.1",
    "electron-log": "^5.3.3",
    "electron-store": "^10.0.1",
    "electron-updater": "^6.3.9",
    "nodejs-whisper": "^0.2.6",
    "openai": "^4.93.0",
    "remixicon": "^4.6.0",
    "tailwindcss": "^4.1.3",
    "uuid": "^11.1.0"
  },
  "devDependencies": {
    "@electron-toolkit/eslint-config-prettier": "^3.0.0",
    "@electron-toolkit/eslint-config-ts": "^3.0.0",
    "@electron-toolkit/tsconfig": "^1.0.1",
    "@sveltejs/vite-plugin-svelte": "^5.0.3",
    "@types/mustache": "^4.2.5",
    "@types/node": "^22.13.13",
    "daisyui": "^5.0.19",
    "electron": "^35.0.3",
    "electron-builder": "^25.1.8",
    "electron-vite": "^3.1.0",
    "eslint": "^9.23.0",
    "eslint-plugin-svelte": "^2.46.1",
    "mustache": "^4.2.0",
    "prettier": "^3.5.3",
    "prettier-plugin-svelte": "^3.3.3",
    "svelte": "^5.25.3",
    "svelte-check": "^4.1.5",
    "typescript": "^5.8.2",
    "vite": "^6.2.3"
  }
}

================
File: plan.md
================
# Vox Transcriber Application Plan

## TODO
Hide widget window when not recording Make sure you can't, if you click on it, something happens in the app, not that you go to the other app Add escape to cancel current transcription Add enhancements prompt to better wave animation

## I. Project Goal

Create an Electron desktop application named "Vox" that:
*   Transcribes audio input using a configurable backend (initially `nodejs-whisper`, with future support for a Whisper API).
*   Supports push-to-talk and toggle recording via configurable global keyboard shortcuts (using a native helper for macOS modifier keys).
*   Pastes the transcribed text into the currently active application (system-wide).
*   Optionally enhances the transcription using LLMs (Gemini, OpenAI, Custom).
*   Provides a settings interface built with Svelte, Tailwind CSS (v4), and DaisyUI (v5) for managing shortcuts, transcription backend, LLM enhancements, custom dictionary, permissions, and viewing history.

## II. Technology Stack

*   **Framework:** Electron
*   **UI:** Svelte
*   **Styling:** Tailwind CSS v4, DaisyUI v5
*   **Transcription Backend (Initial):** `nodejs-whisper` (Node.js native addon)
*   **Transcription Backend (Alternative option):** Whisper API (via HTTP requests)
*   **Global Shortcuts (macOS):** Custom Swift helper tool (`key-monitor`) using `CGEventTap`, managed via `child_process`. Requires Accessibility permissions.
*   **System Paste:** Electron's `clipboard` API + `robotjs` or platform-specific scripts.
*   **State Management:** Svelte Stores (for UI state), simple state management in Main Process.
*   **Audio Recording:** A Node.js compatible library (e.g., `node-audiorecorder`).
*   **Settings Storage:** `electron-store`
*   **Logging:** `electron-log`

## III. High-Level Architecture (with Abstraction)

```mermaid
graph TD
    subgraph Electron Main Process
        subgraph macOS Shortcut Handling
            direction TB
            Z[key-monitor Process (Swift)] -- stdout (KEY_DOWN/UP) --> A;
        end
        A[Shortcut Event Handler] --> B{Transcription Manager};
        G[Settings Storage] --> B;
        B -- Reads Setting --> Selects((Transcription Mode));
        Selects -- Local --> D[LocalWhisperService (nodejs-whisper)];
        Selects -- API --> L[ApiWhisperService (Future)];
        B -- Delegates to --> K{Active Transcription Service};
        D --> K;
        L --> K;
        B --> C[Audio Recorder (Node.js)];
        C -- Audio Data --> K;
        K -- Transcribed Text --> B;
        B --> E[System Paste Handler];
        B --> F[Permissions Manager];
        G --> H[LLM API Handler];
        H --> B;
        B -- Status Updates / Text --> I(Renderer Process);
        E -- Paste Command --> J[OS Clipboard/Input];
        F -- Request Permissions (Mic, Accessibility, Screen Recording) --> M[OS Permissions];
        F -- Starts/Stops --> Z;
        F -- Reads Settings --> Z;
    end

    subgraph Electron Renderer Process (Svelte UI)
        I -- Display Data --> N[Svelte App];
        N -- Settings Changes (incl. Shortcut Keys, Transcription Mode & API details) --> G;
        N -- Request Permission --> F;
        N -- Update Monitored Keys --> A;
        N -- UI Events (e.g., manual start/stop) --> B;
        N -- Display Status/History/Permissions --> O[UI Components];
    end

    style Electron Main Process fill:#f9f,stroke:#333,stroke-width:2px
    style Electron Renderer Process fill:#ccf,stroke:#333,stroke-width:2px
```

**Architecture Notes:**
*   The `Transcription Manager` in the main process selects the active `Transcription Service`.
*   Audio recording and transcription logic reside primarily in the main process.
*   **macOS Shortcut Handling:** A separate Swift process (`key-monitor`) monitors low-level modifier key events and communicates via stdout to the main Electron process (`Shortcut Event Handler`), which implements click/hold/double-click logic. This requires Accessibility permissions for the `key-monitor` executable.
*   The renderer process (Svelte UI) handles displaying information and configuring settings via IPC.

## IV. Detailed Plan

1.  **Phase 1: Project Setup & Core Dependencies [COMPLETED]**
    *   Initialize Svelte, Tailwind CSS v4, DaisyUI v5.
    *   Install `nodejs-whisper` (requires build tools).
    *   Install `robotjs` (or alternative) for system paste simulation.
    *   Install `electron-store`.
    *   Install `electron-log`.
    *   Refine `index.js` and `preload.js` for secure IPC.

2.  **Phase 2: Transcription Core (Main Process)**
    *   Define `TranscriptionService` interface.
    *   Implement `OpenaiWhisperService` using `openai` package.
    *   Implement audio input/recording via Web Audio API (navigator.mediaDevices.getUserMedia)
    *   Implement `Transcription Manager` to select and use the active service based on settings.
    *   Establish IPC for status updates, results, and settings.
    *   Implement recording start/stop on shortcut press/release

3.  **Phase 3: Current Work - OpenAI Whisper API Integration**
    *   Stream audio to OpenAI Whisper API
    *   Handle API responses and display transcription
    *   Implement system paste of transcribed text

4.  **Phase 4: Local Whisper Service & Enhancements**
    *   Implement `LocalWhisperService` using `nodejs-whisper`
    *   Add LLM API calls for text enhancement
    *   Integrate enhancement into transcription flow
    *   Implement history storage using `electron-store`

5.  **Phase 5: Refinement & Packaging**
    *   Add error handling
    *   Optimize performance
    *   Test thoroughly on macOS
    *   Configure Electron Forge/Builder for packaging

## V. Future Considerations
*   Add features utilizing screen recording permission (e.g., screenshot capture).
*   Implement cross-platform global shortcuts using Electron's `globalShortcut`.

================
File: README.md
================
# vox-test

An Electron application with Svelte and TypeScript

## Recommended IDE Setup

- [VSCode](https://code.visualstudio.com/) + [ESLint](https://marketplace.visualstudio.com/items?itemName=dbaeumer.vscode-eslint) + [Prettier](https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode) + [Svelte](https://marketplace.visualstudio.com/items?itemName=svelte.svelte-vscode)

## Project Setup

### Install

```bash
$ npm install
```

### Development

```bash
$ npm run dev
```

### Build

```bash
# For windows
$ npm run build:win

# For macOS
$ npm run build:mac

# For Linux
$ npm run build:linux
```

================
File: svelte.config.mjs
================
import { vitePreprocess } from '@sveltejs/vite-plugin-svelte'

export default {
  // Consult https://svelte.dev/docs#compile-time-svelte-preprocess
  // for more information about preprocessors
  preprocess: vitePreprocess()
}

================
File: tsconfig.json
================
{
  "files": [],
  "references": [{ "path": "./tsconfig.node.json" }, { "path": "./tsconfig.web.json" }]
}

================
File: tsconfig.node.json
================
{
  "extends": "@electron-toolkit/tsconfig/tsconfig.node.json",
  "include": ["electron.vite.config.*", "src/main/**/*", "src/preload/**/*"],
  "compilerOptions": {
    "composite": true,
    "types": ["electron-vite/node"],
    "moduleResolution": "bundler"
  }
}

================
File: tsconfig.web.json
================
{
  "extends": "@electron-toolkit/tsconfig/tsconfig.web.json",
  "include": [
    "src/renderer/src/env.d.ts",
    "src/renderer/src/**/*",
    "src/renderer/src/**/*.svelte",
    "src/preload/*.d.ts"
  ],
  "compilerOptions": {
    "verbatimModuleSyntax": true,
    "useDefineForClassFields": true,
    "strict": false,
    "allowJs": true,
    "checkJs": true,
    "lib": ["ESNext", "DOM", "DOM.Iterable"],
    "moduleResolution": "bundler"
  }
}



================================================================
End of Codebase
================================================================
